# ! pip install transformers
# ! pip install Levenshtein
# ! pip install hazm

import json
import Levenshtein
import re
from torch import where, topk
from torch.nn import functional as F
from hazm import *

#download pretrained model and tokenizer
from transformers import AutoTokenizer, AutoModelForMaskedLM
tokenizer = AutoTokenizer.from_pretrained("HooshvareLab/bert-fa-base-uncased")
model = AutoModelForMaskedLM.from_pretrained("HooshvareLab/bert-fa-base-uncased")

def find_possible_mistakes(inp, model=model, top_k=10000):
  tokens = word_tokenize(inp) # tokenize input
  mistakes = []
  for i, token in enumerate(tokens):
    # print("-----------", token, "-----------")
    token = token.replace("\u200C", "")

    #mask ith word in input
    text = " ".join(tokens[:i]) + tokenizer.mask_token + " ".join(tokens[i+1:])

    # embedding text 
    input = tokenizer.encode_plus(text, return_tensors = "pt")
    mask_index = where(input["input_ids"][0] == tokenizer.mask_token_id)

    logits = model(**input)
    logits = logits.logits
    softmax = F.softmax(logits, dim = -1)
    mask_word = softmax[0, mask_index, :]
    tops = topk(mask_word, top_k, dim = 1)[1][0]

    
    least_dist = float("inf")
    corrected_word = token
    
    for w in tops:
      word = tokenizer.decode([w])
      dist = Levenshtein.distance(token, word)
      if dist < least_dist:
        corrected_word = word
        least_dist = dist

    if token != corrected_word:
      for reg in re.finditer(token, inp):
        s, e = reg.start(), reg.end()
      mistakes.append({"raw": token, "corrected": corrected_word, "span": [s, e]})
  return mistakes

#exmaple:
input0 = "این دانشمند تیرانی باعث افتخار است."
input1 = "پس از سال‌ها تلاش رازی موفق به کسف الکل شد. این دانشمند تیرانی باعث افتخار در تاریخ کور است."
input2 = "بسیاری از مباحث علوم غیرطبیعی با استفاده از فیریک دنیای مادی ابل توجیح نیست و برای یادگیری باید به فلسفه‌های خاصی رجو کرد."
input3 = 'اما متأسفانه به قدری ساختار سارمان سینمایی و در سطح وسیع‌تر وزارت فرهنگ و ارشاد اصلامی عقب‌مانده و ناکارآمد است که عملا جلوی بهبود هر مشکلی را می‌گیرد!'
input4 = 'منطق جغرافیا و جئوپلیتیک همیشه ثابت است و قابل چشم‌پوسی نیست.‎'

print(input2)
result = find_possible_mistakes(input2)
print(result)
