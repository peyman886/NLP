{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "In this assignment, we first take a closer look at Transformer architecture then, we explore some applications of the BERT model.\n",
        "\n",
        "Refrences and useful liks:\n",
        "\n",
        "\n",
        "* [https://self-supervised.cs.jhu.edu/](https://ttps://self-supervised.cs.jhu.edu/)\n",
        "* [https://www.sbert.net/index.html](https://https://www.sbert.net/index.html)\n",
        "* [https://huggingface.co/docs/transformers/model_doc/bert](https://https://huggingface.co/docs/transformers/model_doc/bert)"
      ],
      "metadata": {
        "id": "9f86jDAfKMfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part1: Transformers\n",
        "\n",
        "What do *BERT, RoBERTa, ALBERT, SpanBERT, DistilBERT, SesameBERT, SemBERT, MobileBERT, TinyBERT and CamemBERT* all have in common? And I‚Äôm not looking for the answer ‚ÄúBERT‚Äù ü§≠.\n",
        "Answer: **self-attention** ü§ó. We are not only talking about architectures bearing the name ‚ÄúBERT‚Äô, but more correctly **Transformer-based architectures**. Transformer-based architectures, which are primarily used in modelling language understanding tasks, eschew the use of recurrence in neural network (RNNs) and instead trust entirely on self-attention mechanisms to draw global dependencies between inputs and outputs.\n",
        "\n",
        "\n",
        "**Some useful documentation: ** In the first part of this notebook, we will implement the Transformer architecture by hand.\n",
        "As the architecture is so popular, there already exists a Pytorch module `nn.Transformer`\n",
        "([documentation](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html))\n",
        "and a [tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)\n",
        "on how to use it for next token prediction.\n",
        "However, we will implement it here ourselves, to get through to the smallest details.\n",
        "\n",
        "There are of course many more tutorials out there about attention and Transformers.\n",
        "Below, we list a few that are worth exploring if you are interested in the topic\n",
        "and might want yet another perspective on the topic after this one:\n",
        "\n",
        "* [Transformer: A Novel Neural Network Architecture for Language Understanding\n",
        "(Jakob Uszkoreit, 2017)](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html) - The original Google blog post about the Transformer paper, focusing on the application in machine translation.\n",
        "* [The Illustrated Transformer (Jay Alammar, 2018)](http://jalammar.github.io/illustrated-transformer/) - A very popular and great blog post intuitively explaining the Transformer architecture with many nice visualizations.\n",
        "The focus is on NLP.\n",
        "* [Attention?\n",
        "Attention!\n",
        "(Lilian Weng, 2018)](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html) - A nice blog post summarizing attention mechanisms in many domains including vision.\n",
        "* [Illustrated: Self-Attention (Raimi Karim, 2019)](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a) - A nice visualization of the steps of self-attention.\n",
        "Recommended going through if the explanation below is too abstract for you.\n",
        "* [The Transformer family (Lilian Weng, 2020)](https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html) - A very detailed blog post reviewing more variants of Transformers besides the original one.\n",
        "\n",
        "\n",
        "### What is Attention?\n",
        "\n",
        "The attention mechanism describes a recent new group of layers in neural networks that has attracted\n",
        "a lot of interest in the past few years, especially in sequence tasks.\n",
        "There are a lot of different possible definitions of \"attention\" in the literature,\n",
        "but the one we will use here is the following: _the attention mechanism describes a weighted average\n",
        "of (sequence) elements with the weights dynamically computed based on an input query and elements' keys_.\n",
        "So what does this exactly mean?\n",
        "The goal is to take an average of the features of multiple elements.\n",
        "However, instead of weighting each element equally, we want to weight them depending on their actual values.\n",
        "In other words, we want to dynamically decide on which inputs we want to \"attend\" more than others.\n",
        "In particular, an attention mechanism has usually four parts we need to specify:\n",
        "\n",
        "* **Query**: The query is a feature vector that describes what we are looking for in the sequence, i.e. what would we maybe want to pay attention to.\n",
        "* **Keys**: For each input element, we have a key which is again a feature vector.\n",
        "This feature vector roughly describes what the element is \"offering\", or when it might be important.\n",
        "The keys should be designed such that we can identify the elements we want to pay attention to based on the query.\n",
        "* **Values**: For each input element, we also have a value vector.\n",
        "This feature vector is the one we want to average over.\n",
        "* **Score function**: To rate which elements we want to pay attention to, we need to specify a score function $f_{attn}$.\n",
        "The score function takes the query and a key as input, and outputs the score/attention weight of the query-key pair.\n",
        "It is usually implemented by simple similarity metrics like a dot product, or a small MLP.\n",
        "\n",
        "\n",
        "The weights of the average are calculated by a softmax overall score function outputs.\n",
        "Hence, we assign those value vectors a higher weight whose corresponding key is most similar to the query.\n",
        "If we try to describe it with pseudo-math, we can write:\n",
        "\n",
        "$$\n",
        "\\alpha_i = \\frac{\\exp\\left(f_{attn}\\left(\\text{key}_i, \\text{query}\\right)\\right)}{\\sum_j \\exp\\left(f_{attn}\\left(\\text{key}_j, \\text{query}\\right)\\right)}, \\hspace{5mm} \\text{out} = \\sum_i \\alpha_i \\cdot \\text{value}_i\n",
        "$$\n",
        "\n",
        "Visually, we can show the attention over a sequence of words as follows:\n",
        "\n",
        "<center width=\"100%\" style=\"padding:25px\"><img src=\"https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/05-transformers-and-MH-attention/attention_example.svg\" width=\"750px\"></center>\n",
        "\n",
        "For every word, we have one key and one value vector.\n",
        "The query is compared to all keys with a score function (in this case the dot product) to determine the weights.\n",
        "The softmax is not visualized for simplicity.\n",
        "Finally, the value vectors of all words are averaged using the attention weights.\n",
        "\n",
        "Most attention mechanisms differ in terms of what queries they use, how the key and value vectors are defined,\n",
        "and what score function is used.\n",
        "The attention applied inside the Transformer architecture is called **self-attention**.\n",
        "In self-attention, each sequence element provides a key, value, and query.\n",
        "For each element, we perform an attention layer where based on its query,\n",
        "we check the similarity of all sequence elements' keys and returned a different,\n",
        "averaged value vector for each element.\n",
        "We will now go into a bit more detail by first looking at the specific implementation of the attention mechanism\n",
        "which is in the Transformer case the scaled dot product attention.\n",
        "\n",
        "### Scaled Dot Product Attention\n",
        "\n",
        "The core concept behind self-attention is the scaled dot product attention.\n",
        "Our goal is to have an attention mechanism with which any element in a sequence can attend to any other while\n",
        "still being efficient to compute.\n",
        "The dot product attention takes as input a set of queries\n",
        "$Q\\in\\mathbb{R}^{T\\times d_k}$, keys $K\\in\\mathbb{R}^{T\\times d_k}$\n",
        "and values $V\\in\\mathbb{R}^{T\\times d_v}$ where $T$ is the sequence length,\n",
        "and $d_k$ and $d_v$ are the hidden dimensionality for queries/keys and values respectively.\n",
        "For simplicity, we neglect the batch dimension for now.\n",
        "The attention value from element $i$ to $j$ is based on its similarity of the query $Q_i$ and key $K_j$,\n",
        "using the dot product as the similarity metric.\n",
        "In math, we calculate the dot product attention as follows:\n",
        "\n",
        "$$\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
        "\n",
        "The matrix multiplication $QK^T$ performs the dot product for every possible pair of queries and keys,\n",
        "resulting in a matrix of the shape $T\\times T$.\n",
        "Each row represents the attention logits for a specific element $i$ to all other elements in the sequence.\n",
        "On these, we apply a softmax and multiply with the value vector to obtain a weighted mean\n",
        "(the weights being determined by the attention).\n",
        "Another perspective on this attention mechanism offers the computation graph which is visualized below\n",
        "(figure credit - [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)).\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/05-transformers-and-MH-attention/scaled_dot_product_attn.svg\" width=\"210px\"></center>\n",
        "\n",
        "![texto alternativo](https://miro.medium.com/max/1973/1*G8thyDVqeD8WHim_QzjvFg.gif)\n",
        "\n",
        "\n",
        "One aspect we haven't discussed yet is the scaling factor of $1/\\sqrt{d_k}$.\n",
        "This scaling factor is crucial to maintain an appropriate variance of attention values after initialization.\n",
        "Remember that we initialize our layers to have equal variance throughout the model, and hence,\n",
        "$Q$ and $K$ might also have a variance close to $1$.\n",
        "However, performing a dot product over two vectors with a variance $\\sigma$ results\n",
        "in a scalar having $d_k$-times higher variance:\n",
        "\n",
        "$$q_i \\sim \\mathcal{N}(0,\\sigma), k_i \\sim \\mathcal{N}(0,\\sigma) \\to \\text{Var}\\left(\\sum_{i=1}^{d_k} q_i\\cdot k_i\\right) = \\sigma\\cdot d_k$$\n",
        "\n",
        "\n",
        "If we do not scale down the variance back to $\\sigma$, the softmax over the logits will already saturate\n",
        "to $1$ for one random element and $0$ for all others.\n",
        "The gradients through the softmax will be close to zero so we can't learn the parameters appropriately.\n",
        "\n",
        "\n",
        "*While we will not implement Transformers from scratch, however, we will read and interpret an existing implementation of a Transformer used for implementing the BERT model.*\n",
        "\n"
      ],
      "metadata": {
        "id": "7zEM-4IohtMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 1**\n",
        "Look at the implementation of [`BertSelfAttention`](https://github.com/huggingface/transformers/blob/8b3db33a763ccef828fca89bac7e6cbff314f131/src/transformers/models/bert/modeling_bert.py#L242-L373) in Huggingface. Explain how this implementation ties to the definition of Self-Attention introduced above. Also identify the positional embeddings and how they are implemented. (no more than 20 sentences)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bCGiRmRnPcbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>\n",
        "\n",
        "1. **Initialization**: The class is initialized with configuration parameters that set up the necessary dimensions for the self-attention mechanism. The compatibility of hidden size with the number of attention heads is checked, ensuring each head gets an equal portion of the hidden size.\n",
        "2. **Attention Heads Setup**: It defines the dimensions for each attention head and the combined size for all heads. This allows the model to process different segments of the input data separately within each attention head, a key aspect of the self-attention mechanism.\n",
        "3. **Query, Key, Value Transformations**: Linear transformations create query, key, and value tensors from the input hidden states. These transformations are the first step in calculating attention scores, allowing each position in the input sequence to attend to every other position.\n",
        "4. **Positional Embeddings**: The code supports two types of positional embeddings: absolute and relative. Absolute embeddings are assumed by default, which would be added to the token embeddings outside this class. For relative embeddings, it learns an embedding for each possible relative position between tokens, which is then used to compute attention scores, illustrating the model‚Äôs ability to factor in the order of the input sequence.\n",
        "5. **Attention Scores Calculation**: The raw attention scores are computed by taking the dot product of the query with the key, followed by scaling to stabilize training. This reflects the core self-attention mechanism where a token‚Äôs influence on another is proportional to the dot product of their query and key vectors.\n",
        "6. **Relative Positional Information**: When relative positional embeddings are enabled, they are directly added to the attention scores, which modifies the attention based on the distance between tokens. This is a sophisticated feature allowing the model to understand the sequence context better.\n",
        "7. **Normalization and Masking**: Attention scores are normalized using a softmax function, and any necessary masking is applied to prevent the model from attending to certain positions (like padding tokens), ensuring the model's focus is on valid sequence parts.\n",
        "8. **Context Vector Generation**: Finally, the model computes the context vectors by applying the attention probabilities to the value vectors. The context vectors are a weighted combination of value vectors, with weights indicating the relevance of each token‚Äôs information for the output.\n",
        "9. **Output Structure**: The class returns the context layer, and optionally the attention probabilities, encapsulating the final weighted representations of the input sequence after self-attention has been applied.\n",
        "\n",
        "</font>"
      ],
      "metadata": {
        "id": "xHi9QAt3P8hK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Multi-Head Attention\n",
        "\n",
        "The scaled dot product attention allows a network to attend over a sequence.\n",
        "However, often there are multiple different aspects a sequence element wants to attend to,\n",
        "and a single weighted average is not a good option for it.\n",
        "This is why we extend the attention mechanisms to multiple heads,\n",
        "i.e. multiple different query-key-value triplets on the same features.\n",
        "Specifically, given a query, key, and value matrix, we transform those into $h$ sub-queries, sub-keys,\n",
        "and sub-values, which we pass through the scaled dot product attention independently.\n",
        "Afterward, we concatenate the heads and combine them with a final weight matrix.\n",
        "Mathematically, we can express this operation as:\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "    \\text{Multihead}(Q,K,V) & = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^{O}\\\\\n",
        "    \\text{where } \\text{head}_i & = \\text{Attention}(QW_i^Q,KW_i^K, VW_i^V)\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "We refer to this as Multi-Head Attention layer with the learnable parameters\n",
        "$W_{1...h}^{Q}\\in\\mathbb{R}^{D\\times d_k}$,\n",
        "$W_{1...h}^{K}\\in\\mathbb{R}^{D\\times d_k}$,\n",
        "$W_{1...h}^{V}\\in\\mathbb{R}^{D\\times d_v}$,\n",
        "and $W^{O}\\in\\mathbb{R}^{h\\cdot d_k\\times d_{out}}$ ($D$ being the input dimensionality).\n",
        "Expressed in a computational graph, we can visualize it below\n",
        "(figure credit - [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)).\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/05-transformers-and-MH-attention/multihead_attention.svg\" width=\"230px\"></center>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S9iBGhmvcI9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 2**\n",
        " Again look at the implementation of [`BertSelfAttention`](https://github.com/huggingface/transformers/blob/8b3db33a763ccef828fca89bac7e6cbff314f131/src/transformers/models/bert/modeling_bert.py#L242-L373) in Huggingface. Identify how **multiple heads** of Multi-Head Attention are implemented. Explain your understanding and tie it to the definition introduced above. (no more than 10 sentences)\n"
      ],
      "metadata": {
        "id": "-t6cL5vAPkQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>\n",
        "\n",
        "1. **Attention Heads Setup**: The number of attention heads (`num_attention_heads`) and the size of each head (`attention_head_size`) are defined based on the model's hidden size. This configuration allows the model to have multiple sets of Q, K, and V vectors, one set for each head.\n",
        "2. **Linear Transformations**: Separate linear layers for queries, keys, and values (`self.query`, `self.key`, `self.value`) transform the input hidden states into multiple sets of Q, K, and V vectors. These layers are shared across all attention heads, but they output vectors that are later split into multiple heads.\n",
        "3. **Reshaping for Multi-Head Attention**: The `transpose_for_scores` function reshapes the linear layer outputs to separate the different attention heads. This is done by changing the shape of the tensor from `[batch_size, sequence_length, all_head_size]` to `[batch_size, num_attention_heads, sequence_length, attention_head_size]`.\n",
        "4. **Attention Computation**: Each head computes attention scores independently. The attention mechanism is applied in parallel across the multiple heads, allowing the model to capture different types of information from the input sequence, such as syntactic and semantic features.\n",
        "5. **Concatenation of Heads**: After computing the context vectors for each head, the results are concatenated and potentially reshaped to match the original input dimensionality before being passed to subsequent layers in the model.\n",
        "\n",
        "</font>"
      ],
      "metadata": {
        "id": "sMKpCc_rP3Ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that there is a residual connection and normalization on top of the multi-head attention layer."
      ],
      "metadata": {
        "id": "3wsvLd_KrYqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Screen Shot 2023-02-20 at 8.53.58 PM.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "GERDPIqZr3BG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking as input $x$, it is first passed through a Multi-Head Attention block as we have implemented above.\n",
        "The output is added to the original input using a residual connection,\n",
        "and we apply a consecutive Layer Normalization on the sum.\n",
        "Overall, it calculates $\\text{LayerNorm}(x+\\text{Multihead}(x,x,x))$\n",
        "($x$ being $Q$, $K$ and $V$ input to the attention layer).\n",
        "The residual connection is crucial in the Transformer architecture for two reasons:\n",
        "\n",
        " 1. Similar to ResNets, Transformers are designed to be very deep.\n",
        "Some models contain more than 24 blocks in the encoder.\n",
        "Hence, the residual connections are crucial for enabling a smooth gradient flow through the model.\n",
        " 2. Without the residual connection, the information about the original sequence is lost.\n",
        "Remember that the Multi-Head Attention layer ignores the position of elements in a sequence,\n",
        "and can only learn it based on the input features.\n",
        "Removing the residual connections would mean that this information is lost after the first attention layer\n",
        "(after initialization), and with a randomly initialized query and key vector,\n",
        "the output vectors for position $i$ have no relation to its original input.\n",
        "All outputs of the attention are likely to represent similar/same information,\n",
        "and there is no chance for the model to distinguish which information came from which input element.\n",
        "An alternative option to residual connection would be to fix at least one head to focus on its original input,\n",
        "but this is very inefficient and does not have the benefit of the improved gradient flow.\n",
        "\n",
        "The Layer Normalization also plays an important role in the Transformer architecture as it enables faster\n",
        "training and provides small regularization.\n",
        "Additionally, it ensures that the features are in a similar magnitude among the elements in the sequence.\n",
        "We are not using Batch Normalization because it depends on the batch size which is often small with Transformers\n",
        "(they require a lot of GPU memory), and BatchNorm has shown to perform particularly badly in language\n",
        "as the features of words tend to have a much higher variance (there are many, very rare words\n",
        "which need to be considered for a good distribution estimate).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "McOplQDvr8mt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 3**\n",
        "Look at the implementation of [`BertAttention`](https://github.com/huggingface/transformers/blob/8b3db33a763ccef828fca89bac7e6cbff314f131/src/transformers/models/bert/modeling_bert.py#L390-L437) in Huggingface. Identify how this class loads multi-head self-attention, and combines it with layer-normalization + residual-connection introduced above. (no more than 10 sentences)\n"
      ],
      "metadata": {
        "id": "LaHROfOvsL62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>\n",
        "\n",
        "1. **Instantiation of Multi-Head Self-Attention**: The `BertAttention` class initializes a `BertSelfAttention` object, which handles the computation of multi-head self-attention.\n",
        "2. **Output Layer**: The `BertSelfOutput` is another component initialized within `BertAttention`. It typically handles the transformation of the multi-head attention's output and is where the residual connection and layer normalization would occur.\n",
        "3. **Head Pruning**: The `prune_heads` method allows for the pruning of attention heads, which is a technique to remove certain heads after the model has been trained, potentially reducing the model's size and speeding up inference without a significant loss in performance.\n",
        "4. **Forward Pass**: In the `forward` method, the input `hidden_states` are first passed through the `BertSelfAttention` instance. The resulting outputs are then passed to the `BertSelfOutput` object.\n",
        "5. **Integration with Layer Normalization and Residual Connection**: Although not explicitly shown in this snippet, `BertSelfOutput` is typically responsible for applying a linear transformation to the self-attention outputs, adding a residual connection (by adding the input `hidden_states` to the attention outputs), and normalizing the result with layer normalization.\n",
        "6. **Output Structure**: The class returns a tuple, with the first element being the attention output (after applying self-attention, residual connection, and normalization) and the rest being the outputs from the `BertSelfAttention` layer, which may include the raw attention scores if `output_attentions` is True.\n",
        "</font>"
      ],
      "metadata": {
        "id": "EMVpzuGFPzSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Encoder\n",
        "\n",
        "<div class=\"center-wrapper\"><div class=\"video-wrapper\"><iframe src=\"https://www.youtube.com/embed/QdTgJ85E6YA\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div></div>\n",
        "\n",
        "Originally, the Transformer model was designed for machine translation.\n",
        "Hence, it got an encoder-decoder structure where the encoder takes as input the sentence in the original language\n",
        "and generates an attention-based representation.\n",
        "On the other hand, the decoder attends to the encoded information and generates the translated sentence\n",
        "in an autoregressive manner, as in a standard RNN.\n",
        "While this structure is extremely useful for Sequence-to-Sequence tasks with the necessity of autoregressive decoding,\n",
        "we will focus here on the encoder part.\n",
        "Many advances in NLP have been made using pure encoder-based Transformer models (including\n",
        "[BERT](https://arxiv.org/abs/1810.04805)-family, and more),we will  mainly focus on the **encoder** part.\n",
        "If you have understood the encoder architecture, the decoder is a very small step to implement as well.\n",
        "The full Transformer architecture looks as follows\n",
        "(figure credit - [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)):\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/05-transformers-and-MH-attention/transformer_architecture.svg\" width=\"400px\"></center>\n",
        "\n",
        "The encoder consists of $N$ identical blocks. These blocks contain Self-Attention, Layer Normalization, and Residual connections.\n",
        "\n",
        "\n",
        "Additionally, a small fully connected feed-forward network is added to the model, which is applied to each position separately and identically.\n",
        "Specifically, the model uses a Linear$\\to$ReLU$\\to$Linear MLP.\n",
        "The full transformation including the residual connection can be expressed as:\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "    \\text{FFN}(x) & = \\max(0, xW_1+b_1)W_2 + b_2\\\\\n",
        "    x & = \\text{LayerNorm}(x + \\text{FFN}(x))\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "This MLP adds extra complexity to the model and allows transformations on each sequence element separately.\n",
        "You can imagine as this allows the model to \"post-process\" the new information added\n",
        "by the previous Multi-Head Attention, and prepare it for the next attention block.\n",
        "Usually, the inner dimensionality of the MLP is 2-8$\\times$ larger than $d_{\\text{model}}$,\n",
        "i.e. the dimensionality of the original input $x$.\n",
        "The general advantage of a wider layer instead of a narrow, multi-layer MLP is the faster, parallelizable execution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XGoFr5_FuDIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 4**\n",
        "Look at the implementation of [`BertLayer`](https://github.com/huggingface/transformers/blob/8b3db33a763ccef828fca89bac7e6cbff314f131/src/transformers/models/bert/modeling_bert.py#L468-L551) in Huggingface. Identify how this class creates a complete transformer layer.  In particular, how it incorporates self-attention and ML introduced earlier. (no more than 10 sentences)"
      ],
      "metadata": {
        "id": "Mx6qW4v7PGKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>\n",
        "\n",
        "1. **Initialization**: In the `__init__` method, the class initializes the self-attention mechanism (`BertAttention`) and the feed-forward network components (`BertIntermediate` and `BertOutput`). It also sets up for potential cross-attention layers if the layer is to be used in a decoder context.\n",
        "2. **Forward Pass**: The `forward` method is where the actual computation takes place. The input `hidden_states` are passed through the self-attention mechanism first. If the layer is part of a decoder and cross-attention is added, it handles the attention mechanism using encoder hidden states as well.\n",
        "3. **Self-Attention**: The self-attention module (`self.attention`) performs multi-head self-attention on the `hidden_states`, potentially using past key-value pairs for caching when decoding sequences incrementally.\n",
        "4. **Cross-Attention**: If the layer is in a decoder, cross-attention is computed using the `self.crossattention` module, which attends to the encoder's hidden states.\n",
        "5. **Feed-Forward Network**: The `feed_forward_chunk` method applies the transformer's feed-forward network to the attention output. It involves an intermediate layer (`self.intermediate`) that typically applies a dense layer followed by a GELU activation function, and then another dense layer (`self.output`) that projects the intermediate representation back to the hidden size.\n",
        "6. **Residual Connection and Normalization**: Not explicitly shown in this snippet, but typically, the output of the self-attention and the feed-forward network would each be combined with the original input through a residual connection followed by layer normalization to stabilize the learning process.\n",
        "7. **Outputs**: The class returns the final layer output along with the self-attention outputs (and cross-attention outputs if applicable). If the layer is part of a decoder, it also returns the present key-value pairs for caching.\n",
        "</font>"
      ],
      "metadata": {
        "id": "br9Z3YzjPtXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 5**\n",
        "Look at the implementation of [`BertEncoder`](https://github.com/huggingface/transformers/blob/8b3db33a763ccef828fca89bac7e6cbff314f131/src/transformers/models/bert/modeling_bert.py#L554-L647) in Huggingface. Explain how this class creates a Transformer encoder.  In particular, explain  how it incorporates all the elements discussed thus far to implement the Transformer Encoder (no more than 10 sentences)"
      ],
      "metadata": {
        "id": "3mVtnp3-uDaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>\n",
        "\n",
        "1. **Layer Initialization**: The `BertEncoder` initializes a sequence of transformer layers (`BertLayer` objects) in a `nn.ModuleList`. The number of layers corresponds to `config.num_hidden_layers`. Each `BertLayer` incorporates both a self-attention mechanism and a feed-forward network.\n",
        "2. **Sequential Layer Processing**: During the forward pass, input `hidden_states` are passed through each layer in sequence. The output of each layer is the input to the next, which is the typical behavior of a transformer encoder, allowing for complex feature representations.\n",
        "3. **Attention and Head Mask**: Each layer receives an `attention_mask` and an optional `head_mask`. The `attention_mask` is used to prevent the model from attending to certain positions (e.g., padding tokens), while `head_mask` can be used to mask out attention heads.\n",
        "4. **Gradient Checkpointing**: The `gradient_checkpointing` feature is mentioned, which is an optimization that can save memory during training by trading compute for memory. It's not directly related to the transformer architecture but is important for practical implementations.\n",
        "5. **Cache Mechanism**: The encoder supports caching previous states for efficient decoding in a transformer that's used as a decoder. This is particularly useful in autoregressive decoding.\n",
        "6. **Output Control**: The encoder can optionally output attention weights (`output_attentions`) and hidden states of all layers (`output_hidden_states`). This is helpful for inspection and for some downstream tasks that might require these intermediate representations.\n",
        "7. **Return Type**: The encoder supports returning a dictionary with all relevant outputs (`BaseModelOutputWithPastAndCrossAttentions`), including the last hidden state, cache, all hidden states, self-attentions, and cross-attentions if applicable.\n",
        "8. **Cross-Attention**: If configured (`config.add_cross_attention`), the encoder includes cross-attention layers, which are necessary for a decoder to attend over an encoder's output.\n",
        "9. **Feed-Forward Network**: While not explicitly shown in this snippet, each `BertLayer` contains a feed-forward network (`BertIntermediate` and `BertOutput`), as per the usual transformer model architecture.\n",
        "</font>"
      ],
      "metadata": {
        "id": "DsxoNU7_N-78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part2: Semantic Search\n",
        "\n",
        "Suppose we want to find texts with a similar meaning. For example similar questions in a website like quora. We can use BERT to do so. BERT can gives us an embedding for each token in the text. So we should be able to average over all of them to obtain an embedding for the whole text and compare it with other texts. In this part you will implement semantic search."
      ],
      "metadata": {
        "id": "i4gc2g_GOhS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and setup"
      ],
      "metadata": {
        "id": "8FFLDoxA3P2g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "955011f4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f5c8dbbb"
      },
      "outputs": [],
      "source": [
        "! pip install datasets transformers\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "858b300f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, set_seed\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4a539faf"
      },
      "outputs": [],
      "source": [
        "# Setting seed so the results would be reproducible\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(seed = SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants\n"
      ],
      "metadata": {
        "id": "xG83t6iVWMnt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1cdf78b7"
      },
      "outputs": [],
      "source": [
        "# a model trined for semantic search\n",
        "BASE_MODEL_NAME = 'SeyedAli/Multilingual-Text-Semantic-Search-Siamese-BERT-V1'\n",
        "\n",
        "# you can adjust batch size with your code\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "VSLqEzAOXuke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use 10000 questions from quora dataset and find similar questions to our own question.\n",
        "\n",
        "`query = \"Is Bollywood movies bad?\"`"
      ],
      "metadata": {
        "id": "mxBS0N2oYIyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"toughdata/quora-question-answer-dataset\")"
      ],
      "metadata": {
        "id": "K6mHMWn4lCUm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_samples = 10000\n",
        "dataset =dataset['train'].shuffle(seed=SEED).select([i for i in list(range(num_of_samples))])"
      ],
      "metadata": {
        "id": "Mu7JU0q5I6X3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "OO43r-BGXg6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you will implement utility functions.\n",
        "\n",
        "you should complete the missing parts."
      ],
      "metadata": {
        "id": "BwSMq3jZXltT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pooling(model_output, attention_mask):\n",
        "    # get embeddings from model output\n",
        "    token_embeddings = model_output[0]  # First element of model_output contains token embeddings\n",
        "\n",
        "    # use unsqueeze and expand to match the size\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "\n",
        "    # take the average\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    mean = sum_embeddings / sum_mask\n",
        "\n",
        "    return mean"
      ],
      "metadata": {
        "id": "O3nNPHG_XnPZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(texts, tokenizer, model):\n",
        "    # Tokenize sentences\n",
        "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    # Move to the correct device\n",
        "    encoded_input.to(DEVICE)\n",
        "\n",
        "    # Compute token embeddings by feeding encoded_input to the model\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "\n",
        "    # Perform mean_pooling by using the function just implemented\n",
        "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "    # Normalize embeddings\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "CzITkdW-fxKx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentences we want sentence embeddings for\n",
        "query = \"Is Bollywood movies bad?\"\n",
        "# docs = [q['questions']['text'] for q in dataset]\n",
        "# docs = [q['text'] for q in dataset]\n",
        "docs = dataset['question']\n",
        "# docs = [example['question'] for example in dataset['train']]\n",
        "\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(BASE_MODEL_NAME).to(DEVICE)\n",
        "\n",
        "# Encode query and docs\n",
        "query_emb = encode([query], tokenizer, model)\n",
        "\n",
        "# Since the dataset might be large, we encode the docs in batches.\n",
        "doc_embs = []\n",
        "for start_idx in tqdm(range(0, num_of_samples, BATCH_SIZE)):\n",
        "    end_idx = start_idx + BATCH_SIZE\n",
        "    batch_docs = docs[start_idx:end_idx]\n",
        "    batch_emb = encode(batch_docs, tokenizer, model)\n",
        "    doc_embs.append(batch_emb)\n",
        "\n",
        "# Concatenate the encoded batches\n",
        "doc_emb = torch.cat(doc_embs, dim=0)\n",
        "\n",
        "# Compute dot score between query and all document embeddings\n",
        "scores = torch.mm(query_emb, doc_emb.transpose(0, 1))[0].cpu().tolist()\n",
        "\n",
        "# Combine docs & scores\n",
        "doc_score_pairs = list(zip(docs, scores))\n",
        "doc_score_pairs = list(set(doc_score_pairs))\n",
        "\n",
        "# Sort by decreasing score\n",
        "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Output top-5 scores and their passages\n",
        "top_5 = doc_score_pairs[:5]\n",
        "\n",
        "top_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uz0rdVMaRfS",
        "outputId": "b4079eff-64bf-4a90-9c95-fa78f701aac4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('What are some reasons I should stop watching Bollywood movies?',\n",
              "  0.6865501999855042),\n",
              " ('Which Bollywood movie has a very effective, well crafted, and brilliant climax scene?',\n",
              "  0.6436612606048584),\n",
              " ('Which movie do you feel in Tamil is underrated?', 0.5124212503433228),\n",
              " ('Which Bollywood actresses have viraled their MMS?', 0.5088579058647156),\n",
              " ('What is your worst cinema experience?', 0.4954582750797272)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Sentences we want sentence embeddings for\n",
        "# query = \"Is Bollywood movies bad?\"\n",
        "# docs = dataset['question']\n",
        "\n",
        "# # Load model and tokenizer\n",
        "# ######### Your code begins #########\n",
        "# tokenizer = None\n",
        "# model = None\n",
        "\n",
        "# # Encode query and docs\n",
        "# query_emb = None\n",
        "\n",
        "# # maybe you need to give your data batch by batch to the encode fuction\n",
        "# # so it can fit into memory\n",
        "# doc_emb = None\n",
        "\n",
        "# #Compute dot score between query and all document embeddings\n",
        "# scores = torch.mm(None)[0].cpu().tolist()\n",
        "# ######### Your code ends ###########\n",
        "\n",
        "# #Combine docs & scores\n",
        "# doc_score_pairs = list(zip(docs, scores))\n",
        "\n",
        "# #Sort by decreasing score\n",
        "# doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# #Output top-5 scores and their passages\n",
        "# ######### Your code begins #########\n",
        "# # to do\n",
        "# ######### Your code ends ###########\n",
        "\n"
      ],
      "metadata": {
        "id": "VTUPW4nZOWKO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part3: Token classification\n",
        "\n",
        "Token classification is the task of predicting a label for each token.\n",
        "One of the most common token classification tasks is POS (Part-of-speech tagging) which Grammatically classify the tokens (noun, verb, adjective...).\n",
        "\n",
        "In this last part you are going to read hugging face documentation to fine-tune BERT for the given dataset using trainer API. calculate and report precision, recall, and f1.\n",
        "Finally do an error analysis by printing 5 cases that your model did wrong.\n",
        "\n",
        "Good luckü§ó"
      ],
      "metadata": {
        "id": "4Se30vniagTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TASK = \"pos\" # Part-Of-Speech tagging\n",
        "BASE_MODEL_NAME = \"bert-base-uncased\""
      ],
      "metadata": {
        "id": "VpSOP9OWzu_6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "NUguZ_3beW63"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "L3LxRG0leXbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816db2c6-769c-4ccb-cba3-85b2c74e4979"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "z4s_OI1EjG0G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(BASE_MODEL_NAME)\n",
        "\n",
        "# Tokenize the input (sentences), align the labels with the tokenizer's splitting\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"{TASK}_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n"
      ],
      "metadata": {
        "id": "KwiItDsajOPu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained BERT model for token classification\n",
        "model = BertForTokenClassification.from_pretrained(BASE_MODEL_NAME, num_labels=dataset['train'].features[f\"{TASK}_tags\"].feature.num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj3r5j9OjQ4l",
        "outputId": "501d456b-9933-4ee9-eab8-ee018d13fe7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForTokenClassification(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "uG8q_PgSjVpG",
        "outputId": "fb9af30b-47da-4bd2-effb-e25de23d82c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2634/2634 08:19, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.699800</td>\n",
              "      <td>0.247344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.193800</td>\n",
              "      <td>0.221227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.153800</td>\n",
              "      <td>0.215777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2634, training_loss=0.28370058672303217, metrics={'train_runtime': 499.7388, 'train_samples_per_second': 84.29, 'train_steps_per_second': 5.271, 'total_flos': 1024465153805640.0, 'train_loss': 0.28370058672303217, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function to compute precision, recall, and F1 score\n",
        "def compute_metrics(p):\n",
        "    # print(p)\n",
        "    predictions, labels = p\n",
        "    # print(predictions.shape, labels.shape)\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    # print(predictions.shape)\n",
        "    # Flatten the predictions and labels for all batches\n",
        "    true_predictions = [\n",
        "        p for batch_pred in predictions for p in batch_pred\n",
        "        # p for batch_pred in predictions for p in batch_pred if p != -100\n",
        "\n",
        "    ]\n",
        "    # print(true_predictions)\n",
        "    # print(len(true_predictions))\n",
        "    true_labels = [\n",
        "        l for batch_label in labels for l in batch_label\n",
        "        # l for batch_label in labels for l in batch_label if l != -100\n",
        "\n",
        "    ]\n",
        "    # print(true_labels)\n",
        "    # print(len(true_labels))\n",
        "\n",
        "\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, true_predictions, average='macro')\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }\n",
        "\n",
        "# Set compute_metrics function to the trainer\n",
        "trainer.compute_metrics = compute_metrics\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation_results = trainer.evaluate()\n",
        "\n",
        "# Conduct error analysis\n",
        "predictions, labels, _ = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "predictions = np.argmax(predictions, axis=2)\n"
      ],
      "metadata": {
        "id": "kdQ0pakzYV6V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "b067e070-48b5-4b0c-a165-ea8b416439ee"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 5 examples at random or with specific criteria\n",
        "for i in range(5):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Predictions: {predictions[i]}\")\n",
        "    print(f\"Labels: {labels[i]}\")\n",
        "    print()\n",
        "\n",
        "# Note: The actual selection and printing of incorrect predictions should be more elaborate,\n",
        "# checking where the predictions differ from the labels and then printing the token, prediction, and label.\n"
      ],
      "metadata": {
        "id": "x0Ye2Dsbyld5",
        "outputId": "95fc3fdc-1bf6-4296-b09d-ee397b18e5c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Predictions: [22 22  8 22 22 22 22 22 22 22 22  7  7 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n",
            "Labels: [-100   22    8   22   22   15   22   22   22   22   21    7 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100]\n",
            "\n",
            "Example 2:\n",
            "Predictions: [ 7 22 11  8 11  8 11  7 11 11 11 11 22 11 22 11 11 22 11 11 11 11 22 11\n",
            " 11 22 22 11 11 11 11 11 11 11 11 11 11 11 11 11 11 22 11 11 11 11 11 22\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n",
            "Labels: [-100   22   11 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100]\n",
            "\n",
            "Example 3:\n",
            "Predictions: [ 7 16 22 21  8 21 21 22 22 38 11 15 11 15 22 15 22 38 22 15 12 21 10 11\n",
            " 24 15 11 24 35 37 33 15 12 21 15 12 21 21  7  7 22 21 21 39 21 39 21 15\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n",
            "Labels: [-100   22   22   21 -100 -100 -100   22   22   38   11   15   11   15\n",
            "   22   15   22   38   22   15   12   21   10   11   24   15   11   24\n",
            "   35   37   15   15   12   21   15   12   21   21    7 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100]\n",
            "\n",
            "Example 4:\n",
            "Predictions: [ 7 29 21 15 21  6 15  6 20 37 16  8 40 15 21 24 22  6 22 10 22 12 38 33\n",
            " 15 21 15 22 38 33 15 40 21 15 29 16  8 40 21 15 22  7  7 21 21 21 39 15\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n",
            "Labels: [-100   29   21   15   21    6   30    6   20   37   16 -100 -100   15\n",
            "   21   24   22    6   22   10   22   12   38   33   15   21   15   22\n",
            "   38   33   15   40   21   15   29   16 -100 -100   21   15   22    7\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100]\n",
            "\n",
            "Example 5:\n",
            "Predictions: [ 7 15 39 22 33 15 11 15 12 21 21 15 22 22  6 22 38 29 16 21 15 11 24 15\n",
            " 39 40 33 15 11 15 22 21 41 22 22 22 39 11 15 11  7  7 21 39 39 39 39 39\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n",
            "Labels: [-100   15   39   22   33   15   11   15   12   21   21   15   22   22\n",
            "    6   22   38   29   16   21   15   11   42   15   39   38   33   15\n",
            "   11   15   22   41 -100   22   22 -100   39   11   15   11    7 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            " -100 -100 -100 -100 -100 -100]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Disclosure\n",
        "\n",
        "If you used any AI tools to reach the answer please provide the prompt and the tool that you used. But note that you have to understand the code and the concepts since assignments presentation will be done in person."
      ],
      "metadata": {
        "id": "B7Nm5oZrKh6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ChatGPT"
      ],
      "metadata": {
        "id": "fIka_WhGK2yS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}