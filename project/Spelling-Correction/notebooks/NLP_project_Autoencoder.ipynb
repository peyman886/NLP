{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_project_Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vCK8LnZQBNVM",
        "7leuEyoOvzTx"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCK8LnZQBNVM"
      },
      "source": [
        "# setting gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for use local gpu run this comand in anaconda prompet and copy url and paste on colab:\n",
        "\n",
        "    pip install jupyter_http_over_ws\n",
        "    jupyter serverextension enable --py jupyter_http_over_ws\n",
        "    jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0\n",
        "\n",
        "https://research.google.com/colaboratory/local-runtimes.html  \n"
      ],
      "metadata": {
        "id": "QzI27CQ3cP1N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g36USjN18vKn",
        "outputId": "477a2452-a243-4ebf-e15e-159d30855892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "GeForce RTX 2080 with Max-Q Design\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "      # tf.config.experimental.set_virtual_device_configuration(gpu,\n",
        "      #                                                         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*6)])\n",
        "\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "\n",
        "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
        "  !nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "metadata": {
        "id": "LycGcMqnX9DK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f5829b-1b18-4d2d-d645-fe858a63624c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "GeForce RTX 2080 with Max-Q Design, 461.33, 8192 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# requirement package"
      ],
      "metadata": {
        "id": "7leuEyoOvzTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# !pip install Levenshtein\n",
        "# !pip install transformers\n",
        "# !pip install hazm"
      ],
      "metadata": {
        "id": "hFeT5mhh9fUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "import torch\n",
        "import Levenshtein\n",
        "import re\n",
        "from hazm import *"
      ],
      "metadata": {
        "id": "GAEbF4MnFW0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "# from pandas_profiling import ProfileReport\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns               \n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import warnings                                            \n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "tZWKj1xpY2vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "CYHM4Zm1f001"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "import re"
      ],
      "metadata": {
        "id": "JI4yr5vwpeXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MnkA2aUDqYw",
        "outputId": "3bddb5c7-6cd9-4c01-bbf4-36bf8fbd9534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_hub\n",
            "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\peyma\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\peyma\\anaconda3\\lib\\site-packages (from tensorflow_hub) (3.19.1)\n",
            "Installing collected packages: tensorflow-hub\n",
            "Successfully installed tensorflow-hub-0.12.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.7.3 requires tensorflow<2.8,>=2.7.0, but you have tensorflow 2.9.1 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#all imports\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag \n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Conv2D, Flatten , Input , Conv1D , Concatenate , MaxPooling1D , Dropout , Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import datetime\n",
        "\n",
        "from keras.layers import Concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import Embedding\n",
        "from sklearn.metrics import  f1_score , roc_auc_score\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYp3AGVlDgub",
        "outputId": "b84c9835-8954-43ce-c4b9-293e0b32a799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.1'"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA"
      ],
      "metadata": {
        "id": "vFve7cwmXBsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sZ3FVu0LQKiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tdpeJEu1BHS",
        "outputId": "3c34045b-7d88-4550-cd5c-1034166de6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/NLP/HW3/NLP-HW3-Resources/\n",
        "\n",
        "import zipfile\n",
        "\n",
        "datasets = [\"cultural.zip\", \"economics.zip\", \"politics.zip\", \"sports.zip\"]\n",
        "data = []\n",
        "\n",
        "\n",
        "for dataset in datasets:\n",
        "    with zipfile.ZipFile(dataset) as zipper:\n",
        "        with zipper.open(dataset.split(\".\")[0]+'.txt') as fp:\n",
        "            d = fp.read().decode('utf-8').split('\\n')\n",
        "            data += d #:len(d)//16\n",
        "\n",
        "\n",
        "\n",
        "# %cd /content/drive/MyDrive/NLP/HW3/"
      ],
      "metadata": {
        "id": "HD27Ky5MUf3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= d"
      ],
      "metadata": {
        "id": "sKqK5i0F1RkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(d[:10000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oJBBweizJSO",
        "outputId": "928eadcf-48ea-4fef-c0cf-b8ab7012547e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "همیشه رسم بر این بوده که با تغییر دولت‌ها و روی‌کارآمدن وزرای جدید، رؤسای سازمان سینمایی هم تغییر می‌کنند. برخلاف کشورهای پیشرفته که مدیران نهادهای کلیدی فرهنگی- هنری مثل رؤسای موزه‌های بزرگ، نهادهای سینمایی و هنری به دور از تغییر دولت‌ها بنا بر تخصص خود همچنان به فعالیت هنری خود ادامه می‌دهند، در ایران از بزرگ‌ترین پست‌ها تا کوچک‌ترین سمت‌ها که بعضا حوزه خدماتی را در بر می‌گیرد، تغییر می‌کنند! شاید هم دلیل اصلی آن دولتی‌بودن فرهنگ و هنر است که امر مدیریت را چنین دستخوش تحولات کرده است... به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نهاد ریاست‌جمهوری و حضور محمد اسماعیلی در وزارت فرهنگ و ارشاد اسلامی، محمد خزاعی به‌عنوان رئیس سازمان سینمایی معرفی شد. در پی این انتصاب، تحلیل و نظر برخی از سینماگران را جویا شدیم که می‌خوانید:\n",
            "به صنوف سینمایی سر بزنید!\n",
            "سیدضیا هاشمی. تهیه‌کننده ‌و رئیس جامعه  صنفی تهیه‌کنندگان سینما\n",
            "در شرایط فعلی و با توجه به ناملایماتی که در حوزه سینما وجود دارد، باید اهالی این هنر‌صنعت ایشان را در اداره هرچه بهتر امور کمک کنند. پیوند و اتصالی که می‌تواند میان سینما و تلویزیون با حضور مدیر جدید سازمان صداوسیما آقای پیمان جبلی ایجاد شود، از مأموریت‌های مهم محمد خزاعی به‌شمار می‌آید که همکاری و پیوند این دو رسانه با توجه به سبقه محمد خزاعی و نرمش ایشان در این حوزه همچنین همراهی و مساعدت تهیه‌کنندگان قابل‌دسترس خواهد بود. با این مساعدت می‌توان بحران کرونا را بهتر و راحت‌تر پشت‌سر گذاشت. حضور آقای جبلی نشان از این دارد که ارتباط سینما و تلویزیون نسبت به گذشته بهتر و عمیق‌تر خواهد شد. چه در حوزه تولیدات مشترک و چه در همکاری‌ها میان این دو رسانه می‌توان افق روشنی را شاهد بود.\n",
            "در رسیدن به این چشم‌انداز روشن، تهیه‌کنندگان به‌عنوان مسئولان و صاحبان آثار و کارگردانان به عنوان تولیدکنندگان می‌توانند کمک شایانی داشته باشند. بهتر است‌ محمد خزاعی در جهت روند رو به رشد سینما، شوراهای دست‌وپاگیر را حذف کرده و برای کم‌کردن جشنواره‌ها و اعتباربخشی به جشنواره ملی تلاش کند و تحت تأثیر افراد و توصیه‌های ذی‌نفعان قرار نگیرد. خزاعی تلاش برای کوچک و چابک‌سازی معاونت سینمایی را در اولویت قرار دهد، برگزاری تعدد جشنواره‌ها هیچ کمکی به سینما نمی‌کند و تنها این معاونت را فربه‌تر می‌کند. دو یا سه جشنواره مؤثر می‌تواند در جهت رشد سینما موفق باشد. جشنواره‌هایی که می‌تواند در بخش خصوصی برگزار شود، بهتر است واسپاری شود. دولت نباید در همه زمینه‌ها دخالت کند و جشنواره ملی و بین‌المللی را به یک جشنواره تبدیل کند. جداسازی این جشنواره‌ها نه‌تنها اعتباری برای جشنواره کسب نمی‌کند بلکه هزینه گزافی را برای دولت ایجاد می‌کند. این افتخار ملی را دو‌پاره کردند که اعتباری هم کسب نشد. جشنواره‌های مرتبط می‌تواند در بخش‌های جنبی جشنواره فیلم فجر قرار گیرد که پیش‌تر هم همین روند را شاهد بودیم. اگر قرار است جداگانه جشنواره برگزار شود، بخش خصوصی عهده‌دار برگزاری جشنواره باشد. استفاده از نخبگان در شوراهای وزارت ارشاد، همچنین استفاده از اعضای صنوف در جایگاه خود در شوراها از اهمیت خاصی برخوردار است. مردمی‌بودن تنها در شعار نیست؛ در عمل و رفتار است. ما هنوز بعد از مرحوم سیف‌الله داد معاون سینمایی نداشتیم که به صنوف سرکشی کند و از روند فعالیت آنها مطلع شود. به‌طور نمونه یک روز آقای داد از خیابان شهید کلانتری، محل اتحادیه تهیه‌کنندگان عبور می‌کرد، وقتی چراغ روشن طبقه چهارم را دید، زنگ زد و وارد جلسه شد. گفت جلسه را ادامه دهید، ایشان به‌عنوان مستمع در جلسه نشست و بعد در جلسه وارد بحث‌هایی شد.‌ من بشخصه به تمام معاونین سینمایی پیشنهاد دادم که به صنوف سر بزنند؛ به‌جز یک معاون هیچ‌یک به‌صورت سرزده به صنوف مراجعه نکردند. امروز که محمد خزاعی از دل سینما وارد این حوزه شده است، افرادی که متخصص در این حوزه نیستند، بی‌کسوتان و بی‌برنامه‌ها را از اطرافش دور کند تا بتواند در دوران فعالیت موفق عمل کند. آرزوی سلامت و توفیق برای ایشان دارم.\n",
            "همچون گذشته!\n",
            "فرهاد توحیدی. فیلم‌نامه‌نویس\n",
            "به نظرم سیاست فرهنگی ما عین سیاست خارجی ماست. همان‌گونه که سیاست خارجی ما در وزارت امور خارجه تعیین نمی‌شود، سیاست فرهنگی ما هم در وزارت فرهنگ‌ و ارشاد اسلامی شکل نمی‌گیرد. یا حتی سیاست فرهنگی‌مان در صداوسیما، حوزه هنری سازمان تبلیغات اسلامی و یا هر‌جای دیگری هم شکل نمی‌گیرد. در حقیقت سیاست‌های کلی فرهنگی به‌مثابه بسته‌هایی از پیش تعیین‌شده هستند که در جای دیگری تبیین می‌شوند. بنابراین آقای محمد خزاعی یا دوستان دیگر در قامت مدیران سینمایی مجری آن سیاست‌ها هستند و تنها سلیقه‌های شخصی متناسب با دوری یا نزدیکی از سیاست‌های کلی، ممکن است بیشتر در حوزه مدیریت سینمایی محل اعتنا باشند یا اینکه در حوزه چگونگی اجرای سیاست‌های کلی ممکن است تفاوت‌هایی دیده شود. پس شکل خاصی وجود ندارد که دوستان از خودشان ابداع کرده باشند که مأموریت‌شان مبتنی بر آسیب‌شناسی‌های موجود شکل گرفته باشد!\n",
            "بلکه الگوی اولیه‌ای وجود دارد و دوستان مبتنی بر سلیقه شخصی خود آن را اجرائی می‌کنند. کما اینکه آقای خزاعی در جلسه معارفه‌شان اعلام کردند که دنبال‌کننده سیاست‌های گام دوم انقلاب هستند. بنابراین با ورود رئیس جدید سازمان سینمایی سیاست‌گذاری جدیدی اتفاق نیفتاده‌ بلکه ساختار‌ها همچون گذشته هستند و فقط نوع مدیریت‌ها در شکل پیاده‌کردن سیاست‌های کلی می‌تواند در چارچوب سلایق شخصی افراد پیاده‌سازی و علنی شود.\n",
            "به دادم برس رئیس!\n",
            "جواد طوسی\n",
            "«محمد خزایی» در یکی از بحرانی‌ترین و بی‌رونق‌ترین شرایط حاکم بر سینمای ایران تصدی «سازمان سینمایی» وزارت ارشاد را عهده‌دار شده است. اگر این اِعمال مدیریت با برنامه‌ریزی دقیق و روشن‌بینانه و جسارت در حوزه تصمیم‌گیری توأم نباشد، دیری نخواهد گذشت که تصویری منفی و دافعه‌آمیز از این فرد کم‌و‌بیش موفق در مسئولیت‌های محوله قبلی نزد اهالی سینما شکل خواهد گرفت. سوابق فرهنگی خزایی (دبیری چند دوره از «جشنواره فیلم مقاومت» و دوره‌ای از جشنواره فیلم فجر و تهیه فیلم‌هایی مانند «جعبه موسیقی» فرزاد موتمن، «قلاده‌های طلا» ابوالقاسم طالبی، «پشت پرده مه» و «امپراطور جهنم» پرویز شیخ‌طادی، «پشت دیوار سکوت» مسعود جعفری‌جوزانی و «به وقت شام» ابراهیم حاتمی‌کیا) بیانگر دیدگاه و سلیقه و مبانی اعتقادی اوست. اما یک ویژگی قابل دفاعش را در همان دوره‌ای که جزء اعضای هیئت انتخاب «جشنواره فیلم فجر» بودم، می‌توانم شهادت دهم: انضباط کاری و دخالت‌نکردن در تصمیم‌ها و نقطه‌نظرهای هیئت و آزادی عمل قائل‌شدن برای آنها. از طرفی شناخت محمد خزاعی از محیط سینمای ایران و مسائل و مشکلاتش و سلایق و میزان توانمندی مجموعه افرادش و انعطاف‌پذیری او در تعاملات فرهنگی و هنری، می‌تواند جبران‌کننده نگاه تند و بدبینانه و پرسوءظن وزیر محترم ارشاد در بدو ورودش به این حوزه وزارتی باشد. در واقعیت امر، براساس خصوصیات فردی و شخصیتی خزایی می‌توان خوش‌بین بود که در این شرایط ورشکستگی سینما به‌دنبال تداوم و تشدید هرازگاه ویروس کرونا و تعطیلی پیاپی سینماها و ریزش چشمگیر مخاطبان و روی‌آوردن تعداد قابل‌توجهی از عوامل مختلف سینما به تولیدات شبکه سینمای خانگی با نگاهی متعادل و تفاهم‌آمیز کنار بیاید و اصول‌گرایی و مفاهیم ارزشی و ملّی و ایدئولوژیک را به شیوه‌ای دافعه‌آمیز و جزم‌اندیشانه در حوزه استحفاظی خود تعریف و اجرائی نکند. با این افق دید، انتظار می‌رود که در چرخه مدیریت و سیاست‌گذاری سازمان سینمایی این اولویت‌بندی‌ها صورت گیرد: ۱_ احیای سینما با نگاهی عقلانی و واقع‌بینانه و جذب حداکثری مخاطب با تمهیدات مناسب و هوشمندانه‌ ۲_ توجه به جذابیت و تنوع و وجود کیفی و قابلیت‌های حرفه‌ای در تولیدات سینمایی و تعریف درستِ بازگشت سرمایه با بهادادن بیشتر به یک سینمای کم‌هزینه تا رسیدن به وضعیتی طبیعی و تثبیت‌شده‌ ۳_ بیرون‌آوردن «بخش خصوصی» از رکود و تلاش مُجدّانه برای هویت‌مندی آن در کوتاه‌ترین زمان ممکن‌ ۴ _جهت‌‌دهی درست مخاطب با نگاهی جامعه‌شناسانه و منطبق با واقعیات عینی این دوران و برنامه‌ریزی سنجیده در جهت ارتقای سلیقه و درک بصری او‌ ۵_ ایجاد رقابت سالم و سازنده در میان نسل‌های مختلف فیلم‌ساز و بسترسازی مناسب برای تداوم حیات فرهنگی هنری فیلم‌سازان کهنه‌کار و خوش‌فکر و مستعد و صاحب‌سبک و کاربلد و بیرون‌آوردن آنها از انفعال و انزوا با ردیف بودجه مشخص و ارائه فیلم‌نامه‌های مناسب و وام‌گرفتن از ادبیات داستانی‌ ۶ _ توجه اساسی و خالی از هرگونه شعارگرایی به اجرای «عدالت» در عرصه‌های فرهنگی هنری، به‌گونه‌ای که سینما در سبد فرهنگی اقشار مطرح و آسیب‌پذیر جامعه که طی این سال‌ها توانِ مالی خود را از دست داده‌اند، جایِ دوباره داشته باشد. همچنین این نگرش و نظارت عادلانه از طریق «خانه سینما» درباره تقسیم کار اهالی سینما (به‌ویژه عوامل و صنوف ضعیف و کم‌درآمد) و نحوه حضور قاعده‌مندشان در تولیدات سینمایی و شبکه خانگی، به شکلی صحیح صورت گیرد‌ ۷ _ بازنگری عمیق در سیاست و خط‌مشی و اصول و مبانی کاربردی «بنیاد فارابی» و ایجاد مدیریت کارآمد و حذف مناسبات بوروکراتیک در این مجموعه‌ها به شکلی که سینما بتواند نسبتی درست با جامعه معاصر و طبقه‌بندی آن داشته باشد و درعین‌حال وجوه تجربی و قابلیت‌های حرفه‌ای در امتداد هم در چرخه تولیدات سالانه باز‌تعریف شوند و مابازای عینی و موقعیت نمایشی پیدا کنند و در یک مخاطب‌شناسیِ همگون با قالب زبانی و اجرائی خود قرار بگیرند‌ ۸_ توجه همه‌جانبه به مقوله تاریخ سینما و منابع آرشیوی با ایجاد تحول در بافت سازمانی و حوزه مدیریتی و سیاست‌گذاری «موزه سینما» و «فیلمخانه» وزارت ارشاد‌ ۹_ مذاکره و همفکری پیوسته با «حوزه هنری» و «سازمان صداوسیما» برای تشخص هرچه بیشتر سینما و رسیدن به جایگاه واقعی و تثبیت‌شده‌اش و رسیدن به این درک روشن‌بینانه که حرفه‌ای‌بودن، منافاتی با فرهنگ‌سازشدن ندارد. می‌توان برای اجرائی‌شدن این موارد پیشنهادی از نیروهای مجرب و دلسوز و شناخته‌شده جامعه سینمایی استفاده کرد و به مفهومی متفاوت از «اصولگرایی» در مناسبات فرهنگی رسید. می‌توان هم به ریش ما و این حرف‌ها خندید و این فرصت تاریخی را به دوری باطل و حضوری باری به هرجهت تبدیل کرد، تا یار که را خواهد و میلش به که باشد.\n",
            "سیطره عقلانیت\n",
            "علیرضا رئیسیان. کارگردان  و تهیه‌کننده سینما\n",
            "با توجه به تجربیات گذشته این نسخه را دریافته‌ام، شکل مدیریت در دستگاه‌های اجرائی و به‌ویژه در زمینه‌های فرهنگی همچون صفحه گرامافون می‌ماند که سوزن آن را از اول می‌گذارند و تا آخر همین‌طور یکنواخت می‌چرخد و هربار این حرکت تکرار می‌شود و این تکرار مکررات به شکل بیهوده‌ای بر فرهنگ و به‌خصوص در دو، سه دهه اخیر در سینمای ایران سایه افکنده است!\n",
            "و باید گفت که متأسفانه تا امروز چشم‌انداز متفاوتی ارائه نشده و حتی زمینه‌های تغییرش هم تا الان دیده نشده! که به نظرم چاره‌ای ندارد جز اینکه باید کلا صفحه را عوض کنند تا یک صفحه جدید جایگزین آن شود؛ حتی اگر چنین کاری هم طول بکشد و زمان‌بر باشد اما به دلیل کیفیت‌بخشی آن قابل دفاع است. چون در فضای فرهنگی - هنری کیفیت بر کمیت ارجحیت دارد.\n",
            "اما متأسفانه به قدری ساختار سازمان سینمایی و در سطح وسیع‌تر وزارت فرهنگ و ارشاد اسلامی عقب‌مانده و ناکارآمد است که عملا جلوی بهبود هر مشکلی را می‌گیرد! با این نگاه طبعا آقای خزاعی در این گردبادی که حاصل انفعال عملکرد گذشتگان است قرار گرفته‌اند، نمی‌توان از ایشان انتظار و توقع خاصی داشت. چون ساختار خودش را به مدیر تحمیل می‌کند و طبعا با تجربیاتی که در این سال‌ها کسب کرده‌ام، می‌دانم به‌راحتی نمی‌توان مقابل این فضا ایستاد یا مقاومت کرد. با انبوهی از فیلم‌های در صف اکران، عدم موفقیت پلتفرم‌های نمایش فیلم، سیطره کرونا، بی‌کاری سینماگران، بداستقبالی مخاطبان، فروش پایین فیلم‌ها، دخالت\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uxTKLa7fmpl"
      },
      "source": [
        "**Manipulating the data according to the required Input formatting**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input format required by BERT asks us to add special tokens to the start and end of the sentence, pad and truncate all the sentences to a specific constant length and differentiate the pads from tokens by using attention masks."
      ],
      "metadata": {
        "id": "POEsc5DnaPUD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOCkZY_vWJcK"
      },
      "source": [
        "To get an idea about the length of the description and its corresponding frequency\n",
        "\n",
        "As we have to explicitly pad and truncate all the sentences to a fixed constant length, visualisation of the text length of the cleaned and pre processed data is done in order to select a value that is as close to the actual value (so that we do not lose useful information)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = [len(i.split()) for i in data]"
      ],
      "metadata": {
        "id": "VmhEOnNOXzXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(11.7*2,8.27*2)})\n",
        "his_plot = sns.histplot(seq_len ,bins=500 )\n",
        "his_plot.set(xlim=(0,500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "_8u9NlOXY8Gf",
        "outputId": "634ab4f8-55ea-45d7-8e40-18f6346157d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.0, 500.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1684.8x1190.88 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_len  = pd.DataFrame(seq_len, columns=['length'])\n",
        "df_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3R1CfSQ4aKNo",
        "outputId": "ea030cb9-2ec6-43ee-d246-a993bcb5750b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           length\n",
              "0               1\n",
              "1               1\n",
              "2               1\n",
              "3               1\n",
              "4               1\n",
              "...           ...\n",
              "234775874       1\n",
              "234775875       1\n",
              "234775876       1\n",
              "234775877       0\n",
              "234775878       0\n",
              "\n",
              "[234775879 rows x 1 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234775874</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234775875</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234775876</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234775877</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234775878</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>234775879 rows × 1 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_len.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "c2YYEPKnaLCO",
        "outputId": "e4885944-b21f-46ba-b074-063a4118a91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             length\n",
              "count  2.347759e+08\n",
              "mean   8.126124e-01\n",
              "std    3.902224e-01\n",
              "min    0.000000e+00\n",
              "25%    1.000000e+00\n",
              "50%    1.000000e+00\n",
              "75%    1.000000e+00\n",
              "max    1.000000e+00"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.347759e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.126124e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.902224e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XlG2yAGgjCi"
      },
      "source": [
        "From the above graph, we can see that most of the description lengths are less than 100 words.\n",
        " <!-- **Hence, the MAX_LEN has been chosen to be 128**. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET CREATION (INPUT-OUTPUT PAIR)\n"
      ],
      "metadata": {
        "id": "v4jwo3VtmcY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/NLP/HW3/NLP-HW3-Resources/\n",
        "\n",
        "import zipfile\n",
        "\n",
        "datasets = [\"cultural.zip\", \"economics.zip\", \"politics.zip\", \"sports.zip\"]\n",
        "data = []\n",
        "\n",
        "\n",
        "# for dataset in datasets:\n",
        "dataset = datasets[0]\n",
        "with zipfile.ZipFile(dataset) as zipper:\n",
        "    with zipper.open(dataset.split(\".\")[0]+'.txt') as fp:\n",
        "        d = fp.read().decode('utf-8')\n",
        "        # data += d #:len(d)//16\n",
        "\n",
        "\n",
        "\n",
        "# %cd /content/drive/MyDrive/NLP/HW3/"
      ],
      "metadata": {
        "id": "4L6LxDjdAI2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= d"
      ],
      "metadata": {
        "id": "miwzPd47AI2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(d[:10000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650efe7d-3d03-4cbe-f677-ba8abc936844",
        "id": "qZyOVPQsAI2L"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "همیشه رسم بر این بوده که با تغییر دولت‌ها و روی‌کارآمدن وزرای جدید، رؤسای سازمان سینمایی هم تغییر می‌کنند. برخلاف کشورهای پیشرفته که مدیران نهادهای کلیدی فرهنگی- هنری مثل رؤسای موزه‌های بزرگ، نهادهای سینمایی و هنری به دور از تغییر دولت‌ها بنا بر تخصص خود همچنان به فعالیت هنری خود ادامه می‌دهند، در ایران از بزرگ‌ترین پست‌ها تا کوچک‌ترین سمت‌ها که بعضا حوزه خدماتی را در بر می‌گیرد، تغییر می‌کنند! شاید هم دلیل اصلی آن دولتی‌بودن فرهنگ و هنر است که امر مدیریت را چنین دستخوش تحولات کرده است... به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نهاد ریاست‌جمهوری و حضور محمد اسماعیلی در وزارت فرهنگ و ارشاد اسلامی، محمد خزاعی به‌عنوان رئیس سازمان سینمایی معرفی شد. در پی این انتصاب، تحلیل و نظر برخی از سینماگران را جویا شدیم که می‌خوانید:\n",
            "به صنوف سینمایی سر بزنید!\n",
            "سیدضیا هاشمی. تهیه‌کننده ‌و رئیس جامعه  صنفی تهیه‌کنندگان سینما\n",
            "در شرایط فعلی و با توجه به ناملایماتی که در حوزه سینما وجود دارد، باید اهالی این هنر‌صنعت ایشان را در اداره هرچه بهتر امور کمک کنند. پیوند و اتصالی که می‌تواند میان سینما و تلویزیون با حضور مدیر جدید سازمان صداوسیما آقای پیمان جبلی ایجاد شود، از مأموریت‌های مهم محمد خزاعی به‌شمار می‌آید که همکاری و پیوند این دو رسانه با توجه به سبقه محمد خزاعی و نرمش ایشان در این حوزه همچنین همراهی و مساعدت تهیه‌کنندگان قابل‌دسترس خواهد بود. با این مساعدت می‌توان بحران کرونا را بهتر و راحت‌تر پشت‌سر گذاشت. حضور آقای جبلی نشان از این دارد که ارتباط سینما و تلویزیون نسبت به گذشته بهتر و عمیق‌تر خواهد شد. چه در حوزه تولیدات مشترک و چه در همکاری‌ها میان این دو رسانه می‌توان افق روشنی را شاهد بود.\n",
            "در رسیدن به این چشم‌انداز روشن، تهیه‌کنندگان به‌عنوان مسئولان و صاحبان آثار و کارگردانان به عنوان تولیدکنندگان می‌توانند کمک شایانی داشته باشند. بهتر است‌ محمد خزاعی در جهت روند رو به رشد سینما، شوراهای دست‌وپاگیر را حذف کرده و برای کم‌کردن جشنواره‌ها و اعتباربخشی به جشنواره ملی تلاش کند و تحت تأثیر افراد و توصیه‌های ذی‌نفعان قرار نگیرد. خزاعی تلاش برای کوچک و چابک‌سازی معاونت سینمایی را در اولویت قرار دهد، برگزاری تعدد جشنواره‌ها هیچ کمکی به سینما نمی‌کند و تنها این معاونت را فربه‌تر می‌کند. دو یا سه جشنواره مؤثر می‌تواند در جهت رشد سینما موفق باشد. جشنواره‌هایی که می‌تواند در بخش خصوصی برگزار شود، بهتر است واسپاری شود. دولت نباید در همه زمینه‌ها دخالت کند و جشنواره ملی و بین‌المللی را به یک جشنواره تبدیل کند. جداسازی این جشنواره‌ها نه‌تنها اعتباری برای جشنواره کسب نمی‌کند بلکه هزینه گزافی را برای دولت ایجاد می‌کند. این افتخار ملی را دو‌پاره کردند که اعتباری هم کسب نشد. جشنواره‌های مرتبط می‌تواند در بخش‌های جنبی جشنواره فیلم فجر قرار گیرد که پیش‌تر هم همین روند را شاهد بودیم. اگر قرار است جداگانه جشنواره برگزار شود، بخش خصوصی عهده‌دار برگزاری جشنواره باشد. استفاده از نخبگان در شوراهای وزارت ارشاد، همچنین استفاده از اعضای صنوف در جایگاه خود در شوراها از اهمیت خاصی برخوردار است. مردمی‌بودن تنها در شعار نیست؛ در عمل و رفتار است. ما هنوز بعد از مرحوم سیف‌الله داد معاون سینمایی نداشتیم که به صنوف سرکشی کند و از روند فعالیت آنها مطلع شود. به‌طور نمونه یک روز آقای داد از خیابان شهید کلانتری، محل اتحادیه تهیه‌کنندگان عبور می‌کرد، وقتی چراغ روشن طبقه چهارم را دید، زنگ زد و وارد جلسه شد. گفت جلسه را ادامه دهید، ایشان به‌عنوان مستمع در جلسه نشست و بعد در جلسه وارد بحث‌هایی شد.‌ من بشخصه به تمام معاونین سینمایی پیشنهاد دادم که به صنوف سر بزنند؛ به‌جز یک معاون هیچ‌یک به‌صورت سرزده به صنوف مراجعه نکردند. امروز که محمد خزاعی از دل سینما وارد این حوزه شده است، افرادی که متخصص در این حوزه نیستند، بی‌کسوتان و بی‌برنامه‌ها را از اطرافش دور کند تا بتواند در دوران فعالیت موفق عمل کند. آرزوی سلامت و توفیق برای ایشان دارم.\n",
            "همچون گذشته!\n",
            "فرهاد توحیدی. فیلم‌نامه‌نویس\n",
            "به نظرم سیاست فرهنگی ما عین سیاست خارجی ماست. همان‌گونه که سیاست خارجی ما در وزارت امور خارجه تعیین نمی‌شود، سیاست فرهنگی ما هم در وزارت فرهنگ‌ و ارشاد اسلامی شکل نمی‌گیرد. یا حتی سیاست فرهنگی‌مان در صداوسیما، حوزه هنری سازمان تبلیغات اسلامی و یا هر‌جای دیگری هم شکل نمی‌گیرد. در حقیقت سیاست‌های کلی فرهنگی به‌مثابه بسته‌هایی از پیش تعیین‌شده هستند که در جای دیگری تبیین می‌شوند. بنابراین آقای محمد خزاعی یا دوستان دیگر در قامت مدیران سینمایی مجری آن سیاست‌ها هستند و تنها سلیقه‌های شخصی متناسب با دوری یا نزدیکی از سیاست‌های کلی، ممکن است بیشتر در حوزه مدیریت سینمایی محل اعتنا باشند یا اینکه در حوزه چگونگی اجرای سیاست‌های کلی ممکن است تفاوت‌هایی دیده شود. پس شکل خاصی وجود ندارد که دوستان از خودشان ابداع کرده باشند که مأموریت‌شان مبتنی بر آسیب‌شناسی‌های موجود شکل گرفته باشد!\n",
            "بلکه الگوی اولیه‌ای وجود دارد و دوستان مبتنی بر سلیقه شخصی خود آن را اجرائی می‌کنند. کما اینکه آقای خزاعی در جلسه معارفه‌شان اعلام کردند که دنبال‌کننده سیاست‌های گام دوم انقلاب هستند. بنابراین با ورود رئیس جدید سازمان سینمایی سیاست‌گذاری جدیدی اتفاق نیفتاده‌ بلکه ساختار‌ها همچون گذشته هستند و فقط نوع مدیریت‌ها در شکل پیاده‌کردن سیاست‌های کلی می‌تواند در چارچوب سلایق شخصی افراد پیاده‌سازی و علنی شود.\n",
            "به دادم برس رئیس!\n",
            "جواد طوسی\n",
            "«محمد خزایی» در یکی از بحرانی‌ترین و بی‌رونق‌ترین شرایط حاکم بر سینمای ایران تصدی «سازمان سینمایی» وزارت ارشاد را عهده‌دار شده است. اگر این اِعمال مدیریت با برنامه‌ریزی دقیق و روشن‌بینانه و جسارت در حوزه تصمیم‌گیری توأم نباشد، دیری نخواهد گذشت که تصویری منفی و دافعه‌آمیز از این فرد کم‌و‌بیش موفق در مسئولیت‌های محوله قبلی نزد اهالی سینما شکل خواهد گرفت. سوابق فرهنگی خزایی (دبیری چند دوره از «جشنواره فیلم مقاومت» و دوره‌ای از جشنواره فیلم فجر و تهیه فیلم‌هایی مانند «جعبه موسیقی» فرزاد موتمن، «قلاده‌های طلا» ابوالقاسم طالبی، «پشت پرده مه» و «امپراطور جهنم» پرویز شیخ‌طادی، «پشت دیوار سکوت» مسعود جعفری‌جوزانی و «به وقت شام» ابراهیم حاتمی‌کیا) بیانگر دیدگاه و سلیقه و مبانی اعتقادی اوست. اما یک ویژگی قابل دفاعش را در همان دوره‌ای که جزء اعضای هیئت انتخاب «جشنواره فیلم فجر» بودم، می‌توانم شهادت دهم: انضباط کاری و دخالت‌نکردن در تصمیم‌ها و نقطه‌نظرهای هیئت و آزادی عمل قائل‌شدن برای آنها. از طرفی شناخت محمد خزاعی از محیط سینمای ایران و مسائل و مشکلاتش و سلایق و میزان توانمندی مجموعه افرادش و انعطاف‌پذیری او در تعاملات فرهنگی و هنری، می‌تواند جبران‌کننده نگاه تند و بدبینانه و پرسوءظن وزیر محترم ارشاد در بدو ورودش به این حوزه وزارتی باشد. در واقعیت امر، براساس خصوصیات فردی و شخصیتی خزایی می‌توان خوش‌بین بود که در این شرایط ورشکستگی سینما به‌دنبال تداوم و تشدید هرازگاه ویروس کرونا و تعطیلی پیاپی سینماها و ریزش چشمگیر مخاطبان و روی‌آوردن تعداد قابل‌توجهی از عوامل مختلف سینما به تولیدات شبکه سینمای خانگی با نگاهی متعادل و تفاهم‌آمیز کنار بیاید و اصول‌گرایی و مفاهیم ارزشی و ملّی و ایدئولوژیک را به شیوه‌ای دافعه‌آمیز و جزم‌اندیشانه در حوزه استحفاظی خود تعریف و اجرائی نکند. با این افق دید، انتظار می‌رود که در چرخه مدیریت و سیاست‌گذاری سازمان سینمایی این اولویت‌بندی‌ها صورت گیرد: ۱_ احیای سینما با نگاهی عقلانی و واقع‌بینانه و جذب حداکثری مخاطب با تمهیدات مناسب و هوشمندانه‌ ۲_ توجه به جذابیت و تنوع و وجود کیفی و قابلیت‌های حرفه‌ای در تولیدات سینمایی و تعریف درستِ بازگشت سرمایه با بهادادن بیشتر به یک سینمای کم‌هزینه تا رسیدن به وضعیتی طبیعی و تثبیت‌شده‌ ۳_ بیرون‌آوردن «بخش خصوصی» از رکود و تلاش مُجدّانه برای هویت‌مندی آن در کوتاه‌ترین زمان ممکن‌ ۴ _جهت‌‌دهی درست مخاطب با نگاهی جامعه‌شناسانه و منطبق با واقعیات عینی این دوران و برنامه‌ریزی سنجیده در جهت ارتقای سلیقه و درک بصری او‌ ۵_ ایجاد رقابت سالم و سازنده در میان نسل‌های مختلف فیلم‌ساز و بسترسازی مناسب برای تداوم حیات فرهنگی هنری فیلم‌سازان کهنه‌کار و خوش‌فکر و مستعد و صاحب‌سبک و کاربلد و بیرون‌آوردن آنها از انفعال و انزوا با ردیف بودجه مشخص و ارائه فیلم‌نامه‌های مناسب و وام‌گرفتن از ادبیات داستانی‌ ۶ _ توجه اساسی و خالی از هرگونه شعارگرایی به اجرای «عدالت» در عرصه‌های فرهنگی هنری، به‌گونه‌ای که سینما در سبد فرهنگی اقشار مطرح و آسیب‌پذیر جامعه که طی این سال‌ها توانِ مالی خود را از دست داده‌اند، جایِ دوباره داشته باشد. همچنین این نگرش و نظارت عادلانه از طریق «خانه سینما» درباره تقسیم کار اهالی سینما (به‌ویژه عوامل و صنوف ضعیف و کم‌درآمد) و نحوه حضور قاعده‌مندشان در تولیدات سینمایی و شبکه خانگی، به شکلی صحیح صورت گیرد‌ ۷ _ بازنگری عمیق در سیاست و خط‌مشی و اصول و مبانی کاربردی «بنیاد فارابی» و ایجاد مدیریت کارآمد و حذف مناسبات بوروکراتیک در این مجموعه‌ها به شکلی که سینما بتواند نسبتی درست با جامعه معاصر و طبقه‌بندی آن داشته باشد و درعین‌حال وجوه تجربی و قابلیت‌های حرفه‌ای در امتداد هم در چرخه تولیدات سالانه باز‌تعریف شوند و مابازای عینی و موقعیت نمایشی پیدا کنند و در یک مخاطب‌شناسیِ همگون با قالب زبانی و اجرائی خود قرار بگیرند‌ ۸_ توجه همه‌جانبه به مقوله تاریخ سینما و منابع آرشیوی با ایجاد تحول در بافت سازمانی و حوزه مدیریتی و سیاست‌گذاری «موزه سینما» و «فیلمخانه» وزارت ارشاد‌ ۹_ مذاکره و همفکری پیوسته با «حوزه هنری» و «سازمان صداوسیما» برای تشخص هرچه بیشتر سینما و رسیدن به جایگاه واقعی و تثبیت‌شده‌اش و رسیدن به این درک روشن‌بینانه که حرفه‌ای‌بودن، منافاتی با فرهنگ‌سازشدن ندارد. می‌توان برای اجرائی‌شدن این موارد پیشنهادی از نیروهای مجرب و دلسوز و شناخته‌شده جامعه سینمایی استفاده کرد و به مفهومی متفاوت از «اصولگرایی» در مناسبات فرهنگی رسید. می‌توان هم به ریش ما و این حرف‌ها خندید و این فرصت تاریخی را به دوری باطل و حضوری باری به هرجهت تبدیل کرد، تا یار که را خواهد و میلش به که باشد.\n",
            "سیطره عقلانیت\n",
            "علیرضا رئیسیان. کارگردان  و تهیه‌کننده سینما\n",
            "با توجه به تجربیات گذشته این نسخه را دریافته‌ام، شکل مدیریت در دستگاه‌های اجرائی و به‌ویژه در زمینه‌های فرهنگی همچون صفحه گرامافون می‌ماند که سوزن آن را از اول می‌گذارند و تا آخر همین‌طور یکنواخت می‌چرخد و هربار این حرکت تکرار می‌شود و این تکرار مکررات به شکل بیهوده‌ای بر فرهنگ و به‌خصوص در دو، سه دهه اخیر در سینمای ایران سایه افکنده است!\n",
            "و باید گفت که متأسفانه تا امروز چشم‌انداز متفاوتی ارائه نشده و حتی زمینه‌های تغییرش هم تا الان دیده نشده! که به نظرم چاره‌ای ندارد جز اینکه باید کلا صفحه را عوض کنند تا یک صفحه جدید جایگزین آن شود؛ حتی اگر چنین کاری هم طول بکشد و زمان‌بر باشد اما به دلیل کیفیت‌بخشی آن قابل دفاع است. چون در فضای فرهنگی - هنری کیفیت بر کمیت ارجحیت دارد.\n",
            "اما متأسفانه به قدری ساختار سازمان سینمایی و در سطح وسیع‌تر وزارت فرهنگ و ارشاد اسلامی عقب‌مانده و ناکارآمد است که عملا جلوی بهبود هر مشکلی را می‌گیرد! با این نگاه طبعا آقای خزاعی در این گردبادی که حاصل انفعال عملکرد گذشتگان است قرار گرفته‌اند، نمی‌توان از ایشان انتظار و توقع خاصی داشت. چون ساختار خودش را به مدیر تحمیل می‌کند و طبعا با تجربیاتی که در این سال‌ها کسب کرده‌ام، می‌دانم به‌راحتی نمی‌توان مقابل این فضا ایستاد یا مقاومت کرد. با انبوهی از فیلم‌های در صف اکران، عدم موفقیت پلتفرم‌های نمایش فیلم، سیطره کرونا، بی‌کاری سینماگران، بداستقبالی مخاطبان، فروش پایین فیلم‌ها، دخالت\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_chars = list(\" ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz01234567890\") +\n",
        "input_chars = list(\"ابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی\") + list(\"ئؤأآي\") + list(\"٠١٢٣٤٥٦٧٨٩\") + list('0123456789')+ [' ']\n",
        "# output_chars = [\"<nop>\"] + list(\"،.؟!:؛/()«»\")\n",
        "output_chars = [\"<nop>\"] + list(\".،؛:\") + ['\\u200c'] \n",
        "\n"
      ],
      "metadata": {
        "id": "xKZ8FWFKfvzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHARS = ''\n",
        "for ch in input_chars:\n",
        "  CHARS+=ch\n"
      ],
      "metadata": {
        "id": "1-uw6c_ynmkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHARS = \"\\x00 ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz01234567890.,;:?\\\"'\\n\\r\\t~!@#$%^&*()-/–—=_+<>{}[]|\\\\`~\\xa0ëµ£\"\n",
        "CHARS = CHARS + \".،؛:\" + \"?\\\"'\\n\\r\\t~!@#$%^&*()-/–—=_+<>{}[]|\\\\`~\\xa0ëµ£\" + '\\x00' + '\\u200c'\n",
        "CHARS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLr8cKKmlr12",
        "outputId": "a3d8c215-2b89-44b7-d430-696b0cc76878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهیئؤأآي٠١٢٣٤٥٦٧٨٩0123456789 .،؛:?\"\\'\\n\\r\\t~!@#$%^&*()-/–—=_+<>{}[]|\\\\`~\\xa0ëµ£\\x00\\u200c'"
            ]
          },
          "metadata": {},
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GENERATING INPUT-OUTPUT PAIR"
      ],
      "metadata": {
        "id": "2n13IOwjqAtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #CODE HELP FROM TEXT CLASSIFICATION ASSIGNMENT\n",
        "def pre_process(sample):\n",
        "\n",
        "#     tags = re.compile('<.*?>')\n",
        "#     sample = re.sub(tags, '', sample)\n",
        "    \n",
        "#     sample = re.sub(r'[^\\w]', ' ', sample)\n",
        "\n",
        "#     sample = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", sample)\n",
        "    sample =  sample.replace('\\t', ' ').replace('\\n', '').replace('-', '')#.replace(' ', '')\n",
        "    sample = sample.replace('\\n', '')\n",
        "    sample = sample.replace('...', '.')\n",
        "\n",
        "\n",
        "#     #CODE FROM REFERENCE NOTEBOOK OF DONORS CHOSE DATASET\n",
        "#     def decontracted(phrase):\n",
        "#         # specific\n",
        "#         phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "#         phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "#         # general\n",
        "#         phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "#         phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "#         phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "#         phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "#         phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "#         phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "#         phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "#         phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "#         return phrase\n",
        "#     sample = decontracted(sample)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return (sample)\n"
      ],
      "metadata": {
        "id": "F9Nq8PplqMa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FROM THE CONLL DATASET I VE TAKEN 5 ERROR RULES , ND WILL USE THEM TO GET THE ERRRONEOUS SENTENCES\n",
        "\n",
        "1.Mec Spelling, punctuation, capitalization, etc.\n",
        "\n",
        "2.Vt Verb tense : eg. is / was \n",
        "\n",
        "3.Article or determiner : eg Internet/The internet\n",
        "\n",
        "4.Preposition : eg. below / over\n",
        "\n",
        "5.Redundancy  : eg. repeating words ."
      ],
      "metadata": {
        "id": "ALDzKqDVrCdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preposition = ['about',\n",
        "#  'above',\n",
        "#  'across',\n",
        "#  'after',\n",
        "#  'as',\n",
        "#  'at',\n",
        "#  'before',\n",
        "#  'behind',\n",
        "#  'between',\n",
        "#  'but',\n",
        "#  'by',\n",
        "#  'for',\n",
        "#  'from',\n",
        "#  'in',\n",
        "#  'to',\n",
        "#  'of',\n",
        "#  'off',\n",
        "#  'on',\n",
        "#  'to',\n",
        "#  'until',\n",
        "#  'up',\n",
        "#  'with']\n",
        "\n",
        "preposition = [\n",
        "'از',\n",
        "'با',\n",
        "'بر',\n",
        "'به',\n",
        "'در',\n",
        "# 'توی',\n",
        "'برای',\n",
        "'روی',\n",
        "# 'رو',\n",
        "'زیر',\n",
        "'بالای',\n",
        "'تا',\n",
        "'بعد از',\n",
        "'قبل از',\n",
        "'غیر از',\n",
        "'راجع بع',\n",
        "'درباره ی',\n",
        "'تا',\n",
        "# '',\n",
        "# '',\n",
        "\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "9pO1DpQ5rutC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#CREATING A FNC TO GENERATE ERROR IN SENTENCE\n",
        "# letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "letters    = 'ابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی' + 'ئؤأآي'\n",
        "# len(letters) , letters[0] , letters[25]\n",
        "def generate_error(sentence):\n",
        "    \n",
        "    #THIS WILL DECIDE 2 ERRORS\n",
        "    rand_1 = random.randint(1,8)\n",
        "    rand_2 = random.randint(1,8)\n",
        "#     print(rand_1 , rand_2)\n",
        "    if rand_1 == 1 or rand_2 ==2:\n",
        "        #SPELLING ERROR\n",
        "        #CREATING ERROR IN SENTENCE BY REPLACING A RANDOM WORD IN SENTENTENCE WITH A RANDOM WORD\n",
        "        x = random.randint(0,25)\n",
        "        y = random.randint(0,25)\n",
        "        sentence = sentence.replace(letters[x], letters[y])\n",
        "\n",
        "    elif rand_1 == 2 or rand_2 ==3:\n",
        "        #PREPOSITION ERROR\n",
        "        #CREATING ERROR IN SENTENCE BY DELETING A PREPOSITION\n",
        "        for i in sentence.split() :\n",
        "            if i in preposition:\n",
        "                sentence = re.sub(i[0] , i[1],sentence)\n",
        "\n",
        "\n",
        "    #     #INTRODUCING ARTICLE ERROR\n",
        "    #     #CREATING ERROR IN SENTENCE BY DELETING A ARTICLE AT SOME PLACES\n",
        "    #     sentence = re.sub('an ' , '' , sentence)\n",
        "\n",
        "\n",
        "    #     sentence =  re.sub('a ' , '' , sentence)\n",
        "    #     sentence =  re.sub('the ' , '' , sentence)\n",
        "        \n",
        "        \n",
        "    elif rand_1 == 3 or rand_2 ==4:\n",
        "        #INTRODUCING REDUNDANCY\n",
        "        #REPEATING A WORD IN SENTENCE\n",
        "        rep = sentence.split(' ')\n",
        "        w = random.randint(0,len(rep) - 1)\n",
        "        f = rep[:w + 1] + [rep[w]] + rep[w+1:]\n",
        "        sentence = ' '.join(f)\n",
        "\n",
        "    elif rand_1 == 4 or rand_2 ==5:\n",
        "        sentence = re.sub('\\u200c' , '' , sentence)\n",
        "        sentence = re.sub('.' , '' , sentence)\n",
        "        sentence = re.sub('،' , '' , sentence)\n",
        "\n",
        "\n",
        "\n",
        "    # elif rand_1 == 5 or rand_2 ==6:\n",
        "    #     #OTHER ERRROR : MISSING ERROR\n",
        "    #     #CREATING ERROR IN SENTENCE BY DELETING A RANDOM WORD IN SENTENTENCE \n",
        "    #     print(sentence)\n",
        "    #     delete = sentence.split(' ')\n",
        "    #     w = random.randint(0,len(delete) - 1)\n",
        "    #     sentence = re.sub(delete[w] , '' , sentence)\n",
        "\n",
        "    elif rand_1 == 6 or rand_2 ==7:\n",
        "        sentence = re.sub('\\u200c' , ' ' , sentence) \n",
        "        sentence = re.sub(':' , '' , sentence)\n",
        "        sentence = re.sub('؛' , '' , sentence)\n",
        "\n",
        "    else :\n",
        "        pass\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "fwaPA4QhoajM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = 'سلام، اتفاقاً شما با'\n",
        "k = generate_error(s)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlssWMkdxuw0",
        "outputId": "5bd844da-b716-42db-ee6a-d8afec910d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'سلام، اتفاقاً شما اا'"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one = data\n",
        "sentences_one = one.split('.')\n",
        "sentences_one = [info+'.' for info in sentences_one]\n",
        "type(sentences_one) , len(sentences_one) , sentences_one[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7OJfRbj2fMV",
        "outputId": "50611f88-930d-4690-bd78-181c2edc958a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list,\n",
              " 1566881,\n",
              " ['همیشه رسم بر این بوده که با تغییر دولت\\u200cها و روی\\u200cکارآمدن وزرای جدید، رؤسای سازمان سینمایی هم تغییر می\\u200cکنند.',\n",
              "  ' برخلاف کشورهای پیشرفته که مدیران نهادهای کلیدی فرهنگی- هنری مثل رؤسای موزه\\u200cهای بزرگ، نهادهای سینمایی و هنری به دور از تغییر دولت\\u200cها بنا بر تخصص خود همچنان به فعالیت هنری خود ادامه می\\u200cدهند، در ایران از بزرگ\\u200cترین پست\\u200cها تا کوچک\\u200cترین سمت\\u200cها که بعضا حوزه خدماتی را در بر می\\u200cگیرد، تغییر می\\u200cکنند! شاید هم دلیل اصلی آن دولتی\\u200cبودن فرهنگ و هنر است که امر مدیریت را چنین دستخوش تحولات کرده است.'])"
            ]
          },
          "metadata": {},
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_one = [pre_process(i) for i in tqdm(sentences_one)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emq0O7o12jAh",
        "outputId": "ebfbdacf-e1af-40bc-cf43-7c3c6f87c5c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████| 1566881/1566881 [00:01<00:00, 807750.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in sentences_one:\n",
        "#   print(sentences_one.index(i))\n",
        "\n",
        "#   generate_error(i)\n"
      ],
      "metadata": {
        "id": "D99IeX-U5xmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_sentence_one = [generate_error(i) for i in tqdm(sentences_one)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUc69l7B2liv",
        "outputId": "a5b7ae05-b780-47e7-9f44-3835b3258c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████| 1566881/1566881 [00:17<00:00, 90874.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_one = pd.DataFrame()\n",
        "data_one['input'] = sentences_one\n",
        "data_one['output'] = error_sentence_one\n",
        "print(data_one.shape)\n",
        "data_one.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "l5-m_e222p4U",
        "outputId": "ffbc2552-4a99-4245-94d6-c4a85800e7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1566881, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input  \\\n",
              "0  همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...   \n",
              "1   برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...   \n",
              "2                                                  .   \n",
              "3                                                  .   \n",
              "4   به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...   \n",
              "\n",
              "                                              output  \n",
              "0  همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...  \n",
              "1   برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...  \n",
              "2                                                  .  \n",
              "3                                                . .  \n",
              "4   به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.</td>\n",
              "      <td>. .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...</td>\n",
              "      <td>به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data_one])\n",
        "data.columns =['CORRECT_SENTENCE', 'ERRONEOUS_SENTENCE']\n",
        "print(data.shape)\n",
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "6jNpum073THN",
        "outputId": "f2b80642-bfce-478b-98aa-24b609e6437d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1566881, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    CORRECT_SENTENCE  \\\n",
              "0  همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...   \n",
              "1   برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...   \n",
              "2                                                  .   \n",
              "3                                                  .   \n",
              "4   به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...   \n",
              "5   در پی این انتصاب، تحلیل و نظر برخی از سینماگر...   \n",
              "6   تهیه‌کننده ‌و رئیس جامعه  صنفی تهیه‌کنندگان س...   \n",
              "7   پیوند و اتصالی که می‌تواند میان سینما و تلویز...   \n",
              "8   با این مساعدت می‌توان بحران کرونا را بهتر و ر...   \n",
              "9   حضور آقای جبلی نشان از این دارد که ارتباط سین...   \n",
              "\n",
              "                                  ERRONEOUS_SENTENCE  \n",
              "0  همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...  \n",
              "1   برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...  \n",
              "2                                                  .  \n",
              "3                                                . .  \n",
              "4   به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...  \n",
              "5   در پی این انتصاب، تحلیل و نظر برخی از سینماگر...  \n",
              "6   تهیه‌کننره ‌و رئیس جامعه  صنفی تهیه‌کننرگان س...  \n",
              "7   پیونر و زتصزلی که می‌توزنر میزن سینمز و تلویز...  \n",
              "8                                                     \n",
              "9   حضور آقای جالی نشان از این دارد که ارتااط سین...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CORRECT_SENTENCE</th>\n",
              "      <th>ERRONEOUS_SENTENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.</td>\n",
              "      <td>. .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...</td>\n",
              "      <td>به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>در پی این انتصاب، تحلیل و نظر برخی از سینماگر...</td>\n",
              "      <td>در پی این انتصاب، تحلیل و نظر برخی از سینماگر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>تهیه‌کننده ‌و رئیس جامعه  صنفی تهیه‌کنندگان س...</td>\n",
              "      <td>تهیه‌کننره ‌و رئیس جامعه  صنفی تهیه‌کننرگان س...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>پیوند و اتصالی که می‌تواند میان سینما و تلویز...</td>\n",
              "      <td>پیونر و زتصزلی که می‌توزنر میزن سینمز و تلویز...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>با این مساعدت می‌توان بحران کرونا را بهتر و ر...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>حضور آقای جبلی نشان از این دارد که ارتباط سین...</td>\n",
              "      <td>حضور آقای جالی نشان از این دارد که ارتااط سین...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['CORRECT_SENTENCE'] != '.']\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1SKQRMKc8Y_A",
        "outputId": "83391597-71bb-4e22-81d6-79c8eb8d99bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          CORRECT_SENTENCE  \\\n",
              "0        همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...   \n",
              "1         برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...   \n",
              "4         به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...   \n",
              "5         در پی این انتصاب، تحلیل و نظر برخی از سینماگر...   \n",
              "6         تهیه‌کننده ‌و رئیس جامعه  صنفی تهیه‌کنندگان س...   \n",
              "...                                                    ...   \n",
              "1566875                     هم عمری طولانی و هم كلی مخاطب.   \n",
              "1566876   یوسف رستمی، پژوهشگر ادبی سراغ یكی از شعرهای آ...   \n",
              "1566877   این شعر به امام حسین(ع) تقدیم شده و جدای از ن...   \n",
              "1566878   در صفحه ۱۲ امروز هم غزل منتشرشده و هم تحلیل و...   \n",
              "1566879                          این مطلب را از دست ندهید.   \n",
              "\n",
              "                                        ERRONEOUS_SENTENCE  \n",
              "0        همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...  \n",
              "1         برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...  \n",
              "4         به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...  \n",
              "5         در پی این انتصاب، تحلیل و نظر برخی از سینماگر...  \n",
              "6         تهیه‌کننره ‌و رئیس جامعه  صنفی تهیه‌کننرگان س...  \n",
              "...                                                    ...  \n",
              "1566875                     هم عمری طولانی و هم كلی مخاطب.  \n",
              "1566876   یوسف رسامی، پژوهشگر زدای سرزغ یكی زز شعرهزی آ...  \n",
              "1566877   این شعر به امام حسین(ع) تقدیم شده و جدای از ن...  \n",
              "1566878   رر صفحه ۱۲ امروز هم غزل منتشرشره و هم تحلیل و...  \n",
              "1566879                          این مطلب را از دست ندهید.  \n",
              "\n",
              "[1504458 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CORRECT_SENTENCE</th>\n",
              "      <th>ERRONEOUS_SENTENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...</td>\n",
              "      <td>به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>در پی این انتصاب، تحلیل و نظر برخی از سینماگر...</td>\n",
              "      <td>در پی این انتصاب، تحلیل و نظر برخی از سینماگر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>تهیه‌کننده ‌و رئیس جامعه  صنفی تهیه‌کنندگان س...</td>\n",
              "      <td>تهیه‌کننره ‌و رئیس جامعه  صنفی تهیه‌کننرگان س...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1566875</th>\n",
              "      <td>هم عمری طولانی و هم كلی مخاطب.</td>\n",
              "      <td>هم عمری طولانی و هم كلی مخاطب.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1566876</th>\n",
              "      <td>یوسف رستمی، پژوهشگر ادبی سراغ یكی از شعرهای آ...</td>\n",
              "      <td>یوسف رسامی، پژوهشگر زدای سرزغ یكی زز شعرهزی آ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1566877</th>\n",
              "      <td>این شعر به امام حسین(ع) تقدیم شده و جدای از ن...</td>\n",
              "      <td>این شعر به امام حسین(ع) تقدیم شده و جدای از ن...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1566878</th>\n",
              "      <td>در صفحه ۱۲ امروز هم غزل منتشرشده و هم تحلیل و...</td>\n",
              "      <td>رر صفحه ۱۲ امروز هم غزل منتشرشره و هم تحلیل و...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1566879</th>\n",
              "      <td>این مطلب را از دست ندهید.</td>\n",
              "      <td>این مطلب را از دست ندهید.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1504458 rows × 2 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data.to_csv('data/input_output_new.csv' , index=False)"
      ],
      "metadata": {
        "id": "zfqCLHKP3f_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation for Model"
      ],
      "metadata": {
        "id": "MBb-cL75-mZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data/input_output_new.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sZKWeSq1Ax4E",
        "outputId": "64f876e9-ce5c-47ce-d7a0-712aa0609a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    CORRECT_SENTENCE  \\\n",
              "0  همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...   \n",
              "1   برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...   \n",
              "2   به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...   \n",
              "3   در پی این انتصاب، تحلیل و نظر برخی از سینماگر...   \n",
              "4   تهیه‌کننده ‌و رئیس جامعه  صنفی تهیه‌کنندگان س...   \n",
              "\n",
              "                                  ERRONEOUS_SENTENCE  \n",
              "0  همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...  \n",
              "1   برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...  \n",
              "2                                                NaN  \n",
              "3   در پی این انتصاب، تحلیل و نظر برخی از سینماگر...  \n",
              "4   تهیه‌کننده ‌و ‌و رئیس جامعه  صنفی تهیه‌کنندگا...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CORRECT_SENTENCE</th>\n",
              "      <th>ERRONEOUS_SENTENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>به‌هر‌جهت با استقرار حجت‌الاسلام رئیسی در نها...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>در پی این انتصاب، تحلیل و نظر برخی از سینماگر...</td>\n",
              "      <td>در پی این انتصاب، تحلیل و نظر برخی از سینماگر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>تهیه‌کننده ‌و رئیس جامعه  صنفی تهیه‌کنندگان س...</td>\n",
              "      <td>تهیه‌کننده ‌و ‌و رئیس جامعه  صنفی تهیه‌کنندگا...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "C9mZQ-QkB9yC",
        "outputId": "72ba88c1-2164-44ea-9738-2532398aee9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    CORRECT_SENTENCE  \\\n",
              "0  همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...   \n",
              "1   برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...   \n",
              "\n",
              "                                  ERRONEOUS_SENTENCE  \n",
              "0  همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...  \n",
              "1   برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CORRECT_SENTENCE</th>\n",
              "      <th>ERRONEOUS_SENTENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "      <td>همیشه رسم بر این بوده که با تغییر دولت‌ها و رو...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "      <td>برخلاف کشورهای پیشرفته که مدیران نهادهای کلید...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data.CORRECT_SENTENCE) , data.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgOGdJFuBzIC",
        "outputId": "3e7742af-f182-4fea-cea3-5ded6d4eb342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.series.Series, 211479)"
            ]
          },
          "metadata": {},
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making new data frame with dropped NA values\n",
        "data = data.dropna(axis = 0, how ='any')"
      ],
      "metadata": {
        "id": "KfMtF2mPCKQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length_max = max([len(i) for i in tqdm(data['CORRECT_SENTENCE'])])\n",
        "length_min = min([len(i) for i in tqdm(data['CORRECT_SENTENCE'])])\n",
        "avg = [len(i) for i in tqdm(data['CORRECT_SENTENCE'])]\n",
        "length_avg = np.array([avg]).mean()\n",
        "\n",
        "length_max , length_min , length_avg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHHNxKDQ-pmU",
        "outputId": "49b90ccb-cdfd-4030-8b2d-7144e0323a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████| 1292979/1292979 [00:00<00:00, 2758384.66it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████| 1292979/1292979 [00:00<00:00, 2758380.45it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████| 1292979/1292979 [00:00<00:00, 2740885.90it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20088, 2, 155.4217794720564)"
            ]
          },
          "metadata": {},
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CORRECT_SENTENCE_LEN = data['CORRECT_SENTENCE'].str.split().apply(len) \n",
        "ERRONEOUS_SENTENCE_LEN = data['ERRONEOUS_SENTENCE'].str.split().apply(len)"
      ],
      "metadata": {
        "id": "DVJ6T8KY-3tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(ERRONEOUS_SENTENCE_LEN, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(ERRONEOUS_SENTENCE_LEN, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(ERRONEOUS_SENTENCE_LEN, i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-uWe-rX-5pC",
        "outputId": "eb9009c0-5580-446c-e55a-77745fcdad22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 10.0\n",
            "20 14.0\n",
            "30 18.0\n",
            "40 21.0\n",
            "50 25.0\n",
            "60 29.0\n",
            "70 35.0\n",
            "80 42.0\n",
            "90 54.0\n",
            "100 3024.0\n",
            "90 54.0\n",
            "91 56.0\n",
            "92 58.0\n",
            "93 60.0\n",
            "94 62.0\n",
            "95 66.0\n",
            "96 69.0\n",
            "97 75.0\n",
            "98 82.0\n",
            "99 97.0\n",
            "100 3024.0\n",
            "99.1 99.0\n",
            "99.2 102.0\n",
            "99.3 105.0\n",
            "99.4 110.0\n",
            "99.5 115.0\n",
            "99.6 121.0\n",
            "99.7 131.0\n",
            "99.8 146.0\n",
            "99.9 176.0\n",
            "100 3024.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SINCE 99.2% OF DATA HAS LENGTH LESS THAN 10 , SO SELECTING SENTENCE WITH WORD <100"
      ],
      "metadata": {
        "id": "3gK9JOsi_bUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = 10 \n",
        "\n",
        "data['CORRECT_SENTENCE_LEN'] = data['CORRECT_SENTENCE'].str.split().apply(len)\n",
        "data = data[data['CORRECT_SENTENCE_LEN'] < l]\n",
        "\n",
        "data['ERRONEOUS_SENTENCE_LEN'] = data['ERRONEOUS_SENTENCE'].str.split().apply(len)\n",
        "data = data[data['ERRONEOUS_SENTENCE_LEN'] < l]\n",
        "\n",
        "#ADDING start and end IN THE SENTENCES\n",
        "data['english_inp'] = '<start> ' + data['CORRECT_SENTENCE'].astype(str)\n",
        "data['english_out'] = data['CORRECT_SENTENCE'].astype(str) + ' <end>'\n",
        "\n",
        "data = data.drop(['CORRECT_SENTENCE','CORRECT_SENTENCE_LEN','ERRONEOUS_SENTENCE_LEN'], axis=1)\n",
        "print(data.shape)\n",
        "data.reset_index(inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "Kzr8w9JS_jqy",
        "outputId": "47dc8a35-8c1f-48c6-c4b7-7471682f615c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120192, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                 ERRONEOUS_SENTENCE  \\\n",
              "0     26             آرزوی سلامت و و توفیق برای ایشان دارم.   \n",
              "1     28   فیلم‌نامه‌نویسبه نظرم سیاست فرهنگی ما عین سیا...   \n",
              "2     46                       سیطره عقلانیتعلیرضا رئیسیان.   \n",
              "3     61                         هر‌چند کار بسیار سختی است.   \n",
              "4    121                                                  .   \n",
              "\n",
              "                                         english_inp  \\\n",
              "0      <start>  آرزوی سلامت و توفیق برای ایشان دارم.   \n",
              "1  <start>  فیلم‌نامه‌نویسبه نظرم سیاست فرهنگی ما...   \n",
              "2               <start> سیطره عقلانیتعلیرضا رئیسیان.   \n",
              "3                <start>  هر‌چند کار بسیار سختی است.   \n",
              "4                                         <start>  .   \n",
              "\n",
              "                                         english_out  \n",
              "0         آرزوی سلامت و توفیق برای ایشان دارم. <end>  \n",
              "1   فیلم‌نامه‌نویسبه نظرم سیاست فرهنگی ما عین سیا...  \n",
              "2                 سیطره عقلانیتعلیرضا رئیسیان. <end>  \n",
              "3                   هر‌چند کار بسیار سختی است. <end>  \n",
              "4                                            . <end>  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ERRONEOUS_SENTENCE</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26</td>\n",
              "      <td>آرزوی سلامت و و توفیق برای ایشان دارم.</td>\n",
              "      <td>&lt;start&gt;  آرزوی سلامت و توفیق برای ایشان دارم.</td>\n",
              "      <td>آرزوی سلامت و توفیق برای ایشان دارم. &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>فیلم‌نامه‌نویسبه نظرم سیاست فرهنگی ما عین سیا...</td>\n",
              "      <td>&lt;start&gt;  فیلم‌نامه‌نویسبه نظرم سیاست فرهنگی ما...</td>\n",
              "      <td>فیلم‌نامه‌نویسبه نظرم سیاست فرهنگی ما عین سیا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46</td>\n",
              "      <td>سیطره عقلانیتعلیرضا رئیسیان.</td>\n",
              "      <td>&lt;start&gt; سیطره عقلانیتعلیرضا رئیسیان.</td>\n",
              "      <td>سیطره عقلانیتعلیرضا رئیسیان. &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>هر‌چند کار بسیار سختی است.</td>\n",
              "      <td>&lt;start&gt;  هر‌چند کار بسیار سختی است.</td>\n",
              "      <td>هر‌چند کار بسیار سختی است. &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;start&gt;  .</td>\n",
              "      <td>. &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.ERRONEOUS_SENTENCE[3] , data.english_inp[3] , data.english_out[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVhLs_CE_1_T",
        "outputId": "e53a6cec-41cf-4b35-eb7f-67e9f9e2529a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' هر\\u200cچند کار بسیار سختی است.',\n",
              " '<start>  هر\\u200cچند کار بسیار سختی است.',\n",
              " ' هر\\u200cچند کار بسیار سختی است. <end>')"
            ]
          },
          "metadata": {},
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting train and test"
      ],
      "metadata": {
        "id": "7xTBcH5xAbY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data, test_size=0.2)"
      ],
      "metadata": {
        "id": "K__JQVf6Aehr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape, validation.shape)\n",
        "#ADDING TO <end> TO ONE OF THE SENTENCES SO THAT TOKENIZER LEARNS THE WORD <end>\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
        "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B_RkDXUAhHS",
        "outputId": "ab89e4f0-2354-4b44-87e5-79a8f812c389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96153, 4) (24039, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_encoder_length = max([len(i) for i in tqdm(train['ERRONEOUS_SENTENCE'])])\n",
        "max_decoder_length = max([len(i) for i in tqdm(train['english_inp'])])\n",
        "print(max_encoder_length , max_decoder_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeviNGNeArKb",
        "outputId": "adfb4a3f-69ea-4deb-d5f0-d4db71cf4026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████| 96153/96153 [00:00<00:00, 1220430.48it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████| 96153/96153 [00:00<00:00, 1752937.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136 144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.sample(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wNIE8EXUA-Br",
        "outputId": "17f45e66-3e2e-411b-ffcc-0e7a3e30f510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        index                                 ERRONEOUS_SENTENCE  \\\n",
              "75436  756788    اسامي نامزدهاي جايزه‌ي ادبي «اورنج» اعلام شدند.   \n",
              "18058  170889                             نقاشی؟نقاشی هم می‌کشم.   \n",
              "\n",
              "                                             english_inp  \\\n",
              "75436  <start>   اسامي نامزدهاي جايزه‌ي ادبي «اورنج» ...   \n",
              "18058                     <start> نقاشی؟نقاشی هم می‌کشم.   \n",
              "\n",
              "                                             english_out  \n",
              "75436    اسامي نامزدهاي جايزه‌ي ادبي «اورنج» اعلام شد...  \n",
              "18058                       نقاشی؟نقاشی هم می‌کشم. <end>  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ERRONEOUS_SENTENCE</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75436</th>\n",
              "      <td>756788</td>\n",
              "      <td>اسامي نامزدهاي جايزه‌ي ادبي «اورنج» اعلام شدند.</td>\n",
              "      <td>&lt;start&gt;   اسامي نامزدهاي جايزه‌ي ادبي «اورنج» ...</td>\n",
              "      <td>اسامي نامزدهاي جايزه‌ي ادبي «اورنج» اعلام شد...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18058</th>\n",
              "      <td>170889</td>\n",
              "      <td>نقاشی؟نقاشی هم می‌کشم.</td>\n",
              "      <td>&lt;start&gt; نقاشی؟نقاشی هم می‌کشم.</td>\n",
              "      <td>نقاشی؟نقاشی هم می‌کشم. &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation.sample(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "-F8drvczA_m2",
        "outputId": "b28c387a-d26e-41c9-db4e-b328858cbd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        index ERRONEOUS_SENTENCE english_inp english_out\n",
              "30613  266829                  .  <start>  .     . <end>\n",
              "66854  639091                 4.  <start> 4.    4. <end>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ERRONEOUS_SENTENCE</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30613</th>\n",
              "      <td>266829</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;start&gt;  .</td>\n",
              "      <td>. &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66854</th>\n",
              "      <td>639091</td>\n",
              "      <td>4.</td>\n",
              "      <td>&lt;start&gt; 4.</td>\n",
              "      <td>4. &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOKENIING"
      ],
      "metadata": {
        "id": "oAdxwflRBkk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_ERRONEOUS_SENTENCE = Tokenizer()\n",
        "tknizer_ERRONEOUS_SENTENCE.fit_on_texts(train['ERRONEOUS_SENTENCE'].values)\n",
        "tknizer_CORRECT_SENTENCE = Tokenizer()\n",
        "tknizer_CORRECT_SENTENCE.fit_on_texts(train['english_inp'].values)"
      ],
      "metadata": {
        "id": "Z0RVpx1dBvBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_CORRECT_SENTENCE=len(tknizer_CORRECT_SENTENCE.word_index.keys())\n",
        "print(vocab_size_CORRECT_SENTENCE)\n",
        "vocab_size_ERRONEOUS_SENTENCE=len(tknizer_ERRONEOUS_SENTENCE.word_index.keys())\n",
        "print(vocab_size_ERRONEOUS_SENTENCE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wws2ZlEEIqz",
        "outputId": "db233c45-be4b-4b4e-d241-ab723cb2bfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64792\n",
            "79977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_CORRECT_SENTENCE.word_index['']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "fg0ELUZQUzZ6",
        "outputId": "4fc341be-8daa-4e1c-d23a-8535442b6872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Input \u001b[1;32mIn [388]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtknizer_CORRECT_SENTENCE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'end'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_CORRECT_SENTENCE.word_index['start'], tknizer_CORRECT_SENTENCE.word_index['end']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "HgoXXlMbELHg",
        "outputId": "22459fe6-a53b-48d5-98a0-09421dc02c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Input \u001b[1;32mIn [382]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tknizer_CORRECT_SENTENCE\u001b[38;5;241m.\u001b[39mword_index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mtknizer_CORRECT_SENTENCE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'end'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoConfig, AutoTokenizer, TFAutoModel\n",
        "\n",
        "# config = AutoConfig.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "# model = TFAutoModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "\n",
        "# text = \"ما در هوشواره معتقدیم با انتقال صحیح دانش و آگاهی، همه افراد می‌توانند از ابزارهای هوشمند استفاده کنند. شعار ما هوش مصنوعی برای همه است.\"\n",
        "# tokenizer.tokenize(text)\n"
      ],
      "metadata": {
        "id": "E_KDlDzDFbyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
        "# # mask_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
        "# input"
      ],
      "metadata": {
        "id": "9-LESv2QHQ1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOKENIZER WITH ENGLISH WORDS"
      ],
      "metadata": {
        "id": "g28WJUyEGbjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "model = GPT2LMHeadModel.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "generator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':256})\n",
        "sample = generator('در یک اتفاق شگفت انگیز، پژوهشگران')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQQACFvkJ7_R",
        "outputId": "b1fc898a-fd2d-48e4-fb15-ae44f0176320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:9 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dh7upTDjQw-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = dict()\n",
        "\n",
        "for word, coef in tokenizer.vocab.items():\n",
        "    embeddings_index[word] = coef\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_CORRECT_SENTENCE+1, 100))\n",
        "for word, i in tknizer_CORRECT_SENTENCE.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89jfKE1mGaTu",
        "outputId": "f9ff8dfe-e413-4343-8fe5-3bcfb32b3a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64793, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoEncoder"
      ],
      "metadata": {
        "id": "3aaf-GDjN0fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, input_length, enc_units):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.enc_units= enc_units\n",
        "        self.lstm_output = 0\n",
        "        self.lstm_state_h=0\n",
        "        self.lstm_state_c=0\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\", input_shape=(self.vocab_size,))\n",
        "        self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    def call(self, input_sentances, training=True):\n",
        "        input_embedd                        = self.embedding(input_sentances)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "    def get_states(self):\n",
        "        return self.lstm_state_h,self.lstm_state_c"
      ],
      "metadata": {
        "id": "icHB2hXlNoW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, input_length, dec_units):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.dec_units = dec_units\n",
        "        self.input_length = input_length\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        # we are using embedding_matrix weights and not training the embedding layer\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix],input_shape=(self.vocab_size,))\n",
        "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    def call(self, target_sentances, state_h, state_c):\n",
        "        target_embedd           = self.embedding(target_sentances)\n",
        "        lstm_output, _,_        = self.lstm(target_embedd, initial_state=[state_h, state_c])\n",
        "        return lstm_output"
      ],
      "metadata": {
        "id": "o0wwSyKdN-xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pipeline"
      ],
      "metadata": {
        "id": "6XlAh4HlOA-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, max_len):\n",
        "        self.encoder_inps = data['ERRONEOUS_SENTENCE'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_CORRECT_SENTENCE = tknizer_CORRECT_SENTENCE\n",
        "        self.tknizer_ERRONEOUS_SENTENCE = tknizer_ERRONEOUS_SENTENCE\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ERRONEOUS_SENTENCE.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_CORRECT_SENTENCE.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_CORRECT_SENTENCE.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)"
      ],
      "metadata": {
        "id": "CVieHjBIOHnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataloder(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        \n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        \n",
        "        return [batch[0],batch[1]],batch[2]\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "metadata": {
        "id": "i_HHaCG5OIUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "hX5tKqGNOMOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class vanilla_model(Model):\n",
        "    def __init__(self, encoder_inputs_length,decoder_inputs_length, output_vocab_size):\n",
        "        super().__init__() \n",
        "        self.encoder = Encoder(vocab_size=vocab_size_ERRONEOUS_SENTENCE + 1, embedding_dim=100, input_length=encoder_inputs_length, enc_units=256)\n",
        "        self.decoder = Decoder(vocab_size=vocab_size_CORRECT_SENTENCE + 1, embedding_dim=100, input_length=decoder_inputs_length, dec_units=256)\n",
        "        self.dense   = Dense(output_vocab_size, activation='softmax')\n",
        "        \n",
        "        \n",
        "    def call(self, data):\n",
        "        input,output = data[0], data[1]\n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
        "        decoder_output                       = self.decoder(output, encoder_h, encoder_c)\n",
        "        output                               = self.dense(decoder_output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "pkAg2XFGOOzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = Dataset(train, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, 16)\n",
        "# test_dataset  = Dataset(validation, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, 16)\n",
        "\n",
        "train_dataset = Dataset(train, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, l)\n",
        "test_dataset  = Dataset(validation, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, l)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=512)\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSRz7mFdOSmX",
        "outputId": "f4e22a74-edec-4b8c-ec1a-16ff4eaabc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 10) (512, 10) (512, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "_Ty8Hp1ZOkp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla = vanilla_model(encoder_inputs_length=l,decoder_inputs_length=l,output_vocab_size=vocab_size_CORRECT_SENTENCE)\n",
        "optimizer = tf.keras.optimizers.Adam(clipnorm=1.0)\n",
        "vanilla.compile(optimizer= optimizer, loss= loss_function, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "E-BX6ZK_Omj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "vanilla.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "#TRANING THE MODEL FOR 50 EPOCHS CAUSE , MORE TRAINING GIVES MORE RESULTS\n",
        "vanilla.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=150 , validation_data=train_dataloader, validation_steps=valid_steps )#, callbacks=[stp, chkpt, tfboard]\n",
        "# model_1.fit_generator(train_dataloader,  epochs=4, validation_data=train_dataloader)\n",
        "vanilla.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XoAP3dHMOnIb",
        "outputId": "53984e25-fc62-41a5-8467-9ddda42103be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Input \u001b[1;32mIn [400]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m valid_steps\u001b[38;5;241m=\u001b[39mvalidation\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#TRANING THE MODEL FOR 50 EPOCHS CAUSE , MORE TRAINING GIVES MORE RESULTS\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mvanilla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_steps\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, callbacks=[stp, chkpt, tfboard]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# model_1.fit_generator(train_dataloader,  epochs=4, validation_data=train_dataloader)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m vanilla\u001b[38;5;241m.\u001b[39msummary()\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2260\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2249\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m \n\u001b[0;32m   2251\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2252\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2255\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2256\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2259\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "Input \u001b[1;32mIn [396]\u001b[0m, in \u001b[0;36mvanilla_model.call\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     11\u001b[0m encoder_output, encoder_h, encoder_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m     12\u001b[0m decoder_output                       \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output, encoder_h, encoder_c)\n\u001b[1;32m---> 13\u001b[0m output                               \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"dense_7\" (type Dense).\n\nOOM when allocating tensor with shape[512,10,64792] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Softmax]\n\nCall arguments received by layer \"dense_7\" (type Dense):\n  • inputs=tf.Tensor(shape=(512, 10, 256), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DKoQjVIPKp6",
        "outputId": "5456928e-b1b7-46b7-cd15-9f4b35b7cf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vanilla_model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_7 (Encoder)         multiple                  8363368   \n",
            "                                                                 \n",
            " decoder_7 (Decoder)         multiple                  6844868   \n",
            "                                                                 \n",
            " dense_7 (Dense)             multiple                  16651544  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,859,780\n",
            "Trainable params: 31,859,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ATTENTION"
      ],
      "metadata": {
        "id": "78yfneXEV7Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#all imports\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag \n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Conv2D, Flatten , Input , Conv1D , Concatenate , MaxPooling1D , Dropout , Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import datetime\n",
        "\n",
        "from keras.layers import Concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import Embedding\n",
        "from sklearn.metrics import  f1_score , roc_auc_score\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_54xDTBHV-65",
        "outputId": "cd33c300-014c-40e6-ecaa-875a4f6fac30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.1'"
            ]
          },
          "metadata": {},
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implement custom encoder decoder and attention layers**\n"
      ],
      "metadata": {
        "id": "rAKVUNmBWIYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder**\n"
      ],
      "metadata": {
        "id": "NJtS7BSnWNt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.inp_vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size= lstm_size\n",
        "        self.lstm_output = 0\n",
        "        self.lstm_state_h=0\n",
        "        self.lstm_state_c=0\n",
        "        \n",
        "        self.embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        input_embedd = self.embedding(input_sequence)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd, states)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      self.lstm_state_h = tf.zeros([batch_size , self.lstm_size])\n",
        "      self.lstm_state_c = tf.zeros([batch_size , self.lstm_size])\n",
        "      return self.lstm_state_h,self.lstm_state_c"
      ],
      "metadata": {
        "id": "PRNyrmZUWMRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention**\n"
      ],
      "metadata": {
        "id": "crxxIOnFWVFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super(Attention, self).__init__()\n",
        "    self.scoring_function = scoring_function\n",
        "    self.att_units = att_units\n",
        "    self.W1 = tf.keras.layers.Dense(att_units)\n",
        "    self.W2 = tf.keras.layers.Dense(att_units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    \n",
        "    if self.scoring_function == 'dot':\n",
        "        decoder_hidden_state_reshaped = tf.reshape(decoder_hidden_state , (decoder_hidden_state.shape[0],decoder_hidden_state.shape[1],1))\n",
        "\n",
        "        #I WAS USING tf.keras.layers.Dot FOR DOT PRODUCT , BUT IT GAVE INCOMPATIBILITY IN SHAPES , SO NOW I VE USED tf.keras.layers.dot\n",
        "        score =  tf.keras.layers.dot([ encoder_output , decoder_hidden_state_reshaped] , [2,1]) \n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vector = attention_weights * encoder_output  #\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "        pass\n",
        "    elif self.scoring_function == 'general':\n",
        "        decoder_hidden_state_reshaped = tf.reshape(decoder_hidden_state , (decoder_hidden_state.shape[0],decoder_hidden_state.shape[1],1))\n",
        "        W = tf.random.uniform(shape=[encoder_output.shape[0] , self.att_units , self.att_units])\n",
        "        score =  tf.keras.layers.dot([ encoder_output , W] , [2,1]) \n",
        "        score =  tf.keras.layers.dot([ score , decoder_hidden_state_reshaped] , [2,1]) \n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vector = attention_weights * encoder_output  #\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "        pass\n",
        "    elif self.scoring_function == 'concat':\n",
        "\n",
        "        decoder_hidden_state_reshaped = tf.expand_dims(decoder_hidden_state, 1)\n",
        "        score =  self.V(tf.nn.tanh(self.W1(decoder_hidden_state_reshaped) + self.W2(encoder_output)) )\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * encoder_output  #\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "        pass\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "ql-3SKlUWSpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OneStepDecoder**"
      ],
      "metadata": {
        "id": "Wbu8bJ9YWYi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "    def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "        super(One_Step_Decoder, self).__init__()\n",
        "\n",
        "        # Initialize decoder embedding layer, LSTM \n",
        "        self.tar_vocab_size = tar_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.dec_units = dec_units\n",
        "        self.score_fun = score_fun\n",
        "        self.att_units = att_units\n",
        "\n",
        "        self.attention=Attention(score_fun,att_units)\n",
        "        self.embedding = tf.keras.layers.Embedding(tar_vocab_size, embedding_dim)\n",
        "        self.lstm = LSTM(self.dec_units , return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n",
        "        self.dense = tf.keras.layers.Dense(self.tar_vocab_size)\n",
        "\n",
        "    def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "        output = self.embedding(input_to_decoder) # (32, 1, 12)\n",
        "        context_vector,attention_weights=self.attention(state_h,encoder_output)\n",
        "        concat = tf.concat([tf.expand_dims(context_vector, 1), output], axis=-1)\n",
        "        lstm_output, state_h, state_c = self.lstm(concat)\n",
        "        \n",
        "        output = self.dense(lstm_output)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        return output,state_h,state_c,attention_weights,context_vector"
      ],
      "metadata": {
        "id": "0oOTAKblWV3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder**"
      ],
      "metadata": {
        "id": "d7x1M-tCWdBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "        super(Decoder , self).__init__()\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.dec_units = dec_units\n",
        "        self.score_fun = score_fun\n",
        "        self.att_units = att_units\n",
        "\n",
        "        self.onestep_decoder=One_Step_Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "\n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        all_outputs = tf.TensorArray(tf.float32, size=tf.shape(input_to_decoder)[1])\n",
        "        for timestep in range(tf.shape(input_to_decoder)[1]):\n",
        "            output,state_h,state_c,attention_weights,context_vector = self.onestep_decoder(input_to_decoder[: , timestep : timestep + 1] , \\\n",
        "                                                                                           encoder_output , decoder_hidden_state , decoder_cell_state)\n",
        "\n",
        "\n",
        "            all_outputs = all_outputs.write(timestep , output)\n",
        "        all_outputs = tf.transpose(all_outputs.stack() , [1,0,2])\n",
        "        return all_outputs"
      ],
      "metadata": {
        "id": "BactmhFSWeWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_vocab_size=13 \n",
        "embedding_dim=12 \n",
        "input_length=10\n",
        "dec_units=16 \n",
        "att_units=16\n",
        "batch_size=32\n",
        "\n",
        "target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "score_fun = 'concat'\n",
        "decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIiC4wi3Whsf",
        "outputId": "5325e709-0186-4330-ab99-fabd4929c296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 10, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder Decoder model**\n"
      ],
      "metadata": {
        "id": "MYCbtOuHWxa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, max_len):\n",
        "        self.encoder_inps = data['ERRONEOUS_SENTENCE'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_CORRECT_SENTENCE = tknizer_CORRECT_SENTENCE\n",
        "        self.tknizer_ERRONEOUS_SENTENCE = tknizer_ERRONEOUS_SENTENCE\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ERRONEOUS_SENTENCE.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_CORRECT_SENTENCE.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_CORRECT_SENTENCE.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "\n",
        "class Dataloder(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        \n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        \n",
        "        return [batch[0],batch[1]],batch[2]\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "metadata": {
        "id": "a7gAVShNWtUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = Dataset(train, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, 16)\n",
        "# test_dataset  = Dataset(validation, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, 16)\n",
        "\n",
        "train_dataset = Dataset(train, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, 20)\n",
        "test_dataset  = Dataset(validation, tknizer_ERRONEOUS_SENTENCE, tknizer_CORRECT_SENTENCE, 20)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=512)\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83_v4FOQWyBz",
        "outputId": "c2f466f5-0066-4b99-d26c-488689ce7a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 20) (512, 20) (512, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "    def __init__(self,score_fun , encoder_inputs_length,decoder_inputs_length, output_vocab_size):\n",
        "        super().__init__()\n",
        "        #encoder decoder\n",
        "\n",
        "        self.score_fun = score_fun\n",
        "\n",
        "        self.encoder=Encoder(inp_vocab_size = vocab_size_ERRONEOUS_SENTENCE+1,embedding_size = 50,lstm_size = 64,input_length = encoder_inputs_length)\n",
        "        self.decoder=Decoder(out_vocab_size = vocab_size_CORRECT_SENTENCE+1, embedding_dim = 100, input_length = decoder_inputs_length, dec_units =  64 \\\n",
        "                             ,score_fun = self.score_fun ,att_units = 64)\n",
        "\n",
        "    def call(self,data):\n",
        "\n",
        "        input,output = data[0], data[1]\n",
        "        initial_state= self.encoder.initialize_states(batch_size)\n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input , initial_state)\n",
        "\n",
        "        decoder_output= self.decoder(output,encoder_output, encoder_h, encoder_c)\n",
        "\n",
        "        return decoder_output"
      ],
      "metadata": {
        "id": "TrNi2jZ_W7b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=512\n",
        "score_fun  = 'general'\n",
        "att_units = 64\n",
        "model_2  = encoder_decoder(score_fun = score_fun , encoder_inputs_length=20,decoder_inputs_length=10,output_vocab_size=vocab_size_CORRECT_SENTENCE)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model_2.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "#TRANING THE MODEL FOR 20 EPOCHS CAUSE , MORE TRAINING GIVES MORE RESULTS\n",
        "log_dir=\"logs1\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "checkpoint = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "model_2.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=150, validation_data=train_dataloader, validation_steps=valid_steps , callbacks = checkpoint)\n",
        "# model_1.fit_generator(train_dataloader,  epochs=4, validation_data=train_dataloader)\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v8BX5Sp3W9eF",
        "outputId": "2b6d4d4e-9709-46e9-e61d-2354cf2a8dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Input \u001b[1;32mIn [415]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39mlog_dir,histogram_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, write_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,write_grads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_steps\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# model_1.fit_generator(train_dataloader,  epochs=4, validation_data=train_dataloader)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model_2\u001b[38;5;241m.\u001b[39msummary()\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2260\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2249\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m \n\u001b[0;32m   2251\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2252\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2255\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2256\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2258\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2259\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "Input \u001b[1;32mIn [414]\u001b[0m, in \u001b[0;36mencoder_decoder.call\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     15\u001b[0m initial_state\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39minitialize_states(batch_size)\n\u001b[0;32m     16\u001b[0m encoder_output, encoder_h, encoder_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\u001b[38;5;28minput\u001b[39m , initial_state)\n\u001b[1;32m---> 18\u001b[0m decoder_output\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoder_output\n",
            "Input \u001b[1;32mIn [410]\u001b[0m, in \u001b[0;36mDecoder.call\u001b[1;34m(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state)\u001b[0m\n\u001b[0;32m     17\u001b[0m     output,state_h,state_c,attention_weights,context_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monestep_decoder(input_to_decoder[: , timestep : timestep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] , \\\n\u001b[0;32m     18\u001b[0m                                                                                    encoder_output , decoder_hidden_state , decoder_cell_state)\n\u001b[0;32m     21\u001b[0m     all_outputs \u001b[38;5;241m=\u001b[39m all_outputs\u001b[38;5;241m.\u001b[39mwrite(timestep , output)\n\u001b[1;32m---> 22\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mall_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m , [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_outputs\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"decoder_10\" (type Decoder).\n\nOOM when allocating tensor with shape[20,512,64793] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Pack] name: packed\n\nCall arguments received by layer \"decoder_10\" (type Decoder):\n  • input_to_decoder=tf.Tensor(shape=(512, 20), dtype=int32)\n  • encoder_output=tf.Tensor(shape=(512, 20, 64), dtype=float32)\n  • decoder_hidden_state=tf.Tensor(shape=(512, 64), dtype=float32)\n  • decoder_cell_state=tf.Tensor(shape=(512, 64), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhM_EZsfXOcq",
        "outputId": "b1bb895e-2160-4e0e-ba62-1bf1299ea697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_8 (Encoder)         multiple                  4028340   \n",
            "                                                                 \n",
            " decoder_10 (Decoder)        multiple                  10749469  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,777,809\n",
            "Trainable params: 14,777,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}